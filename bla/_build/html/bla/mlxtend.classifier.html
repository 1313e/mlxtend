<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>mlxtend.classifier package &mdash; classifier --maxdepth=7 documentation</title>
    
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '--maxdepth=7',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="classifier --maxdepth=7 documentation" href="../index.html" />
   
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9">

  </head>
  <body role="document">  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="mlxtend-classifier-package">
<h1>mlxtend.classifier package<a class="headerlink" href="#mlxtend-classifier-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-mlxtend.classifier.adaline">
<span id="mlxtend-classifier-adaline-module"></span><h2>mlxtend.classifier.adaline module<a class="headerlink" href="#module-mlxtend.classifier.adaline" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mlxtend.classifier.adaline.Adaline">
<em class="property">class </em><code class="descclassname">mlxtend.classifier.adaline.</code><code class="descname">Adaline</code><span class="sig-paren">(</span><em>eta=0.01</em>, <em>epochs=50</em>, <em>learning='sgd'</em>, <em>random_seed=None</em>, <em>shuffle=False</em>, <em>zero_init_weight=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/adaline.html#Adaline"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.adaline.Adaline" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>ADAptive LInear NEuron classifier.</p>
<dl class="docutils">
<dt>eta <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Learning rate (between 0.0 and 1.0)</dd>
<dt>epochs <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Passes over the training dataset.</dd>
<dt>learning <span class="classifier-delimiter">:</span> <span class="classifier">str (default: sgd)</span></dt>
<dd>Gradient decent (gd) or stochastic gradient descent (sgd)</dd>
<dt>shuffle <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>Shuffles training data every epoch if True to prevent circles.</dd>
<dt>random_seed <span class="classifier-delimiter">:</span> <span class="classifier">int (default: None)</span></dt>
<dd>Set random state for shuffling and initializing the weights.</dd>
<dt>zero_init_weight <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>If True, weights are initialized to zero instead of small random
numbers in the interval [0,1]</dd>
</dl>
<dl class="docutils">
<dt><a href="#id1"><span class="problematic" id="id2">w_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">1d-array</span></dt>
<dd>Weights after fitting.</dd>
<dt><a href="#id3"><span class="problematic" id="id4">cost_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>Sum of squared errors after each epoch.</dd>
</dl>
<dl class="method">
<dt id="mlxtend.classifier.adaline.Adaline.activation">
<code class="descname">activation</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/adaline.html#Adaline.activation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.adaline.Adaline.activation" title="Permalink to this definition">¶</a></dt>
<dd><p>Activation function</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.adaline.Adaline.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>init_weights=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/adaline.html#Adaline.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.adaline.Adaline.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit training data.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values.</dd>
<dt>init_weights <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: True)</span></dt>
<dd>(Re)initializes weights to small random floats if True.</dd>
</dl>
<p>self : object</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.adaline.Adaline.net_input">
<code class="descname">net_input</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/adaline.html#Adaline.net_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.adaline.Adaline.net_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Net input function</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.adaline.Adaline.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/adaline.html#Adaline.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.adaline.Adaline.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>class <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Predicted class label.</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mlxtend.classifier.ensemble">
<span id="mlxtend-classifier-ensemble-module"></span><h2>mlxtend.classifier.ensemble module<a class="headerlink" href="#module-mlxtend.classifier.ensemble" title="Permalink to this headline">¶</a></h2>
<p>Soft Voting/Majority Rule classifier</p>
<p>This module contains a Soft Voting/Majority Rule classifier for
classification clfs.</p>
<dl class="class">
<dt id="mlxtend.classifier.ensemble.EnsembleClassifier">
<em class="property">class </em><code class="descclassname">mlxtend.classifier.ensemble.</code><code class="descname">EnsembleClassifier</code><span class="sig-paren">(</span><em>clfs</em>, <em>voting='hard'</em>, <em>weights=None</em>, <em>verbose=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.ensemble.EnsembleClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.BaseEstimator</span></code>, <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.ClassifierMixin</span></code>, <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.TransformerMixin</span></code></p>
<p>Soft Voting/Majority Rule classifier for unfitted clfs.</p>
<dl class="docutils">
<dt>clfs <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_classifiers]</span></dt>
<dd>A list of classifiers.
Invoking the <cite>fit</cite> method on the <cite>VotingClassifier</cite> will fit clones
of those original classifiers that will be stored in the class attribute
<cite>self.clfs_</cite>.</dd>
<dt>voting <span class="classifier-delimiter">:</span> <span class="classifier">str, {&#8216;hard&#8217;, &#8216;soft&#8217;} (default=&#8217;hard&#8217;)</span></dt>
<dd>If &#8216;hard&#8217;, uses predicted class labels for majority rule voting.
Else if &#8216;soft&#8217;, predicts the class label based on the argmax of
the sums of the predicted probalities, which is recommended for
an ensemble of well-calibrated classifiers.</dd>
<dt>weights <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_classifiers], optional (default=`None`)</span></dt>
<dd>Sequence of weights (<cite>float</cite> or <cite>int</cite>) to weight the occurances of
predicted class labels (<cite>hard</cite> voting) or class probabilities
before averaging (<cite>soft</cite> voting). Uses uniform weights if <cite>None</cite>.</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">int, optional (default=0)</span></dt>
<dd><dl class="first last docutils">
<dt>Controls the verbosity of the building process.</dt>
<dd><p class="first"><cite>verbose=0</cite> (default): Prints nothing
<cite>verbose=1</cite>: Prints the number &amp; name of the clf being fitted
<cite>verbose=2</cite>: Prints info about the parameters of the clf being fitted
<cite>verbose&gt;2</cite>: Changes <cite>verbose</cite> param of the underlying clf to</p>
<blockquote class="last">
<div>self.verbose - 2</div></blockquote>
</dd>
</dl>
</dd>
</dl>
<p><a href="#id5"><span class="problematic" id="id6">classes_</span></a> : array-like, shape = [n_predictions]</p>
<dl class="docutils">
<dt>clf <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_predictions]</span></dt>
<dd>The unmodified input classifiers</dd>
<dt><a href="#id7"><span class="problematic" id="id8">clf_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_predictions]</span></dt>
<dd>Fitted clones of the input classifiers</dd>
</dl>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mlxtend.sklearn</span> <span class="kn">import</span> <span class="n">EnsembleClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf3</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf1</span> <span class="o">=</span> <span class="n">EnsembleClassifier</span><span class="p">(</span><span class="n">clfs</span><span class="o">=</span><span class="p">[</span><span class="n">clf1</span><span class="p">,</span> <span class="n">clf2</span><span class="p">,</span> <span class="n">clf3</span><span class="p">],</span>
<span class="gp">... </span><span class="n">voting</span><span class="o">=</span><span class="s">&#39;hard&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf1</span> <span class="o">=</span> <span class="n">eclf1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">eclf1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="go">[1 1 1 2 2 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf2</span> <span class="o">=</span> <span class="n">EnsembleClassifier</span><span class="p">(</span><span class="n">clfs</span><span class="o">=</span><span class="p">[</span><span class="n">clf1</span><span class="p">,</span> <span class="n">clf2</span><span class="p">,</span> <span class="n">clf3</span><span class="p">],</span> <span class="n">voting</span><span class="o">=</span><span class="s">&#39;soft&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf2</span> <span class="o">=</span> <span class="n">eclf2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">eclf2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="go">[1 1 1 2 2 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf3</span> <span class="o">=</span> <span class="n">EnsembleClassifier</span><span class="p">(</span><span class="n">clfs</span><span class="o">=</span><span class="p">[</span><span class="n">clf1</span><span class="p">,</span> <span class="n">clf2</span><span class="p">,</span> <span class="n">clf3</span><span class="p">],</span>
<span class="gp">... </span>                         <span class="n">voting</span><span class="o">=</span><span class="s">&#39;soft&#39;</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf3</span> <span class="o">=</span> <span class="n">eclf3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">eclf3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="go">[1 1 1 2 2 2]</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
<dl class="method">
<dt id="mlxtend.classifier.ensemble.EnsembleClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.ensemble.EnsembleClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the clfs.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values.</dd>
</dl>
<p>self : object</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.ensemble.EnsembleClassifier.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier.get_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.ensemble.EnsembleClassifier.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Return estimator parameter names for GridSearch support</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.ensemble.EnsembleClassifier.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.ensemble.EnsembleClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>maj <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Predicted class labels.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.ensemble.EnsembleClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.ensemble.EnsembleClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class probabilities for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>avg <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples, n_classes]</span></dt>
<dd>Weighted average probability for each class per sample.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.ensemble.EnsembleClassifier.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.ensemble.EnsembleClassifier.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Return class labels or probabilities for X for each estimator.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>If <cite>voting=&#8217;soft&#8217;</cite>:</dt>
<dd><dl class="first last docutils">
<dt>array-like = [n_classifiers, n_samples, n_classes]</dt>
<dd>Class probabilties calculated by each classifier.</dd>
</dl>
</dd>
<dt>If <cite>voting=&#8217;hard&#8217;</cite>:</dt>
<dd><dl class="first last docutils">
<dt>array-like = [n_classifiers, n_samples]</dt>
<dd>Class labels predicted by each classifier.</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mlxtend.classifier.logistic_regression">
<span id="mlxtend-classifier-logistic-regression-module"></span><h2>mlxtend.classifier.logistic_regression module<a class="headerlink" href="#module-mlxtend.classifier.logistic_regression" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mlxtend.classifier.logistic_regression.LogisticRegression">
<em class="property">class </em><code class="descclassname">mlxtend.classifier.logistic_regression.</code><code class="descname">LogisticRegression</code><span class="sig-paren">(</span><em>eta=0.01</em>, <em>epochs=50</em>, <em>regularization=None</em>, <em>l2_lambda=0.0</em>, <em>learning='sgd'</em>, <em>shuffle=False</em>, <em>random_seed=None</em>, <em>zero_init_weight=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/logistic_regression.html#LogisticRegression"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.logistic_regression.LogisticRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Logistic regression classifier.</p>
<dl class="docutils">
<dt>eta <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Learning rate (between 0.0 and 1.0)</dd>
<dt>epochs <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Passes over the training dataset.</dd>
<dt>learning <span class="classifier-delimiter">:</span> <span class="classifier">str (default: sgd)</span></dt>
<dd>Learning rule, sgd (stochastic gradient descent)
or gd (gradient descent).</dd>
<dt>regularization <span class="classifier-delimiter">:</span> <span class="classifier">{None, &#8216;l2&#8217;} (default: None)</span></dt>
<dd>Type of regularization. No regularization if
<cite>regularization=None</cite>.</dd>
<dt>l2_lambda <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Regularization parameter for L2 regularization.
No regularization if l2_lambda=0.0.</dd>
<dt>shuffle <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>Shuffles training data every epoch if True to prevent circles.</dd>
<dt>random_seed <span class="classifier-delimiter">:</span> <span class="classifier">int (default: None)</span></dt>
<dd>Set random state for shuffling and initializing the weights.</dd>
<dt>zero_init_weight <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>If True, weights are initialized to zero instead of small random
numbers in the interval [0,1]</dd>
</dl>
<dl class="docutils">
<dt><a href="#id9"><span class="problematic" id="id10">w_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">1d-array</span></dt>
<dd>Weights after fitting.</dd>
<dt><a href="#id11"><span class="problematic" id="id12">cost_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>List of floats with sum of squared error cost (sgd or gd) for every
epoch.</dd>
</dl>
<dl class="method">
<dt id="mlxtend.classifier.logistic_regression.LogisticRegression.activation">
<code class="descname">activation</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/logistic_regression.html#LogisticRegression.activation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.logistic_regression.LogisticRegression.activation" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class probabilities for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<blockquote>
<div>Class 1 probability : float</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.logistic_regression.LogisticRegression.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>init_weights=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/logistic_regression.html#LogisticRegression.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.logistic_regression.LogisticRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit training data.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values.</dd>
<dt>init_weights <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: True)</span></dt>
<dd>(Re)initializes weights to small random floats if True.</dd>
</dl>
<p>self : object</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.logistic_regression.LogisticRegression.net_input">
<code class="descname">net_input</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/logistic_regression.html#LogisticRegression.net_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.logistic_regression.LogisticRegression.net_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Net input function.</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.logistic_regression.LogisticRegression.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/logistic_regression.html#LogisticRegression.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.logistic_regression.LogisticRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>class <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Predicted class label.</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mlxtend.classifier.neuralnet_mlp">
<span id="mlxtend-classifier-neuralnet-mlp-module"></span><h2>mlxtend.classifier.neuralnet_mlp module<a class="headerlink" href="#module-mlxtend.classifier.neuralnet_mlp" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mlxtend.classifier.neuralnet_mlp.NeuralNetMLP">
<em class="property">class </em><code class="descclassname">mlxtend.classifier.neuralnet_mlp.</code><code class="descname">NeuralNetMLP</code><span class="sig-paren">(</span><em>n_output, n_features, n_hidden=30, l1=0.0, l2=0.0, epochs=500, eta=0.001, alpha=0.0, decrease_const=0.0, random_weights=[-1.0, 1.0], shuffle_init=True, shuffle_epoch=True, minibatches=1, random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/neuralnet_mlp.html#NeuralNetMLP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.neuralnet_mlp.NeuralNetMLP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Feedforward neural network / Multi-layer perceptron classifier.</p>
<dl class="docutils">
<dt>n_output <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Number of output units, should be equal to the
number of unique class labels.</dd>
<dt>n_features <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Number of features (dimensions) in the target dataset.
Should be equal to the number of columns in the X array.</dd>
<dt>n_hidden <span class="classifier-delimiter">:</span> <span class="classifier">int (default: 30)</span></dt>
<dd>Number of hidden units.</dd>
<dt>l1 <span class="classifier-delimiter">:</span> <span class="classifier">float (default: 0.0)</span></dt>
<dd>Lambda value for L1-regularization.
No regularization if l1=0.0 (default)</dd>
<dt>l2 <span class="classifier-delimiter">:</span> <span class="classifier">float (default: 0.0)</span></dt>
<dd>Lambda value for L2-regularization.
No regularization if l2=0.0 (default)</dd>
<dt>epochs <span class="classifier-delimiter">:</span> <span class="classifier">int (default: 500)</span></dt>
<dd>Number of passes over the training set.</dd>
<dt>eta <span class="classifier-delimiter">:</span> <span class="classifier">float (default: 0.001)</span></dt>
<dd>Learning rate.</dd>
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float (default: 0.0)</span></dt>
<dd>Momentum constant. Factor multiplied with the
gradient of the previous epoch t-1 to improve
learning speed
w(t) := w(t) - (grad(t) + alpha*grad(t-1))</dd>
<dt>decrease_const <span class="classifier-delimiter">:</span> <span class="classifier">float (default: 0.0)</span></dt>
<dd>Decrease constant. Shrinks the learning rate
after each epoch via eta / (1 + epoch*decrease_const)</dd>
<dt>random_weights <span class="classifier-delimiter">:</span> <span class="classifier">list (default: [-1.0, 1.0])</span></dt>
<dd>Min and max values for initializing the random weights.
Initializes weights to 0 if None or False.</dd>
<dt>shuffle_init <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: True)</span></dt>
<dd>Shuffles (a copy of the) training data before training.</dd>
<dt>shuffle_epoch <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: True)</span></dt>
<dd>Shuffles training data before every epoch if True to prevent circles.</dd>
<dt>minibatches <span class="classifier-delimiter">:</span> <span class="classifier">int (default: 1)</span></dt>
<dd>Divides training data into k minibatches for efficiency.
Normal gradient descent learning if k=1 (default).</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int (default: None)</span></dt>
<dd>Set random state for shuffling and initializing the weights.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id13"><span class="problematic" id="id14">cost_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>Sum of squared errors after each epoch.</dd>
</dl>
<dl class="method">
<dt id="mlxtend.classifier.neuralnet_mlp.NeuralNetMLP.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>print_progress=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/neuralnet_mlp.html#NeuralNetMLP.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.neuralnet_mlp.NeuralNetMLP.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Learn weights from training data.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = [n_samples, n_features]</span></dt>
<dd>Input layer with original features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = [n_samples]</span></dt>
<dd>Target class labels.</dd>
<dt>print_progress <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>Prints progress as the number of epochs
to stderr.</dd>
</dl>
<p>self</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.neuralnet_mlp.NeuralNetMLP.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/neuralnet_mlp.html#NeuralNetMLP.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.neuralnet_mlp.NeuralNetMLP.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = [n_samples, n_features]</span></dt>
<dd>Input layer with original features.</dd>
</dl>
<dl class="docutils">
<dt>y_pred <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = [n_samples]</span></dt>
<dd>Predicted class labels.</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mlxtend.classifier.perceptron">
<span id="mlxtend-classifier-perceptron-module"></span><h2>mlxtend.classifier.perceptron module<a class="headerlink" href="#module-mlxtend.classifier.perceptron" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mlxtend.classifier.perceptron.Perceptron">
<em class="property">class </em><code class="descclassname">mlxtend.classifier.perceptron.</code><code class="descname">Perceptron</code><span class="sig-paren">(</span><em>eta=0.1</em>, <em>epochs=50</em>, <em>shuffle=False</em>, <em>random_state=None</em>, <em>random_weights=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/perceptron.html#Perceptron"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.perceptron.Perceptron" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Perceptron classifier.</p>
<dl class="docutils">
<dt>eta <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Learning rate (between 0.0 and 1.0)</dd>
<dt>epochs <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Passes over the training dataset.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Random state for initializing random weights.</dd>
<dt>random_weights <span class="classifier-delimiter">:</span> <span class="classifier">list (default: [-0.5, 0.5])</span></dt>
<dd>Min and max values for initializing the random weights.
Initializes weights to 0 if None or False.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id15"><span class="problematic" id="id16">w_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">1d-array</span></dt>
<dd>Weights after fitting.</dd>
<dt><a href="#id17"><span class="problematic" id="id18">cost_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>Number of misclassifications in every epoch.</dd>
</dl>
<dl class="method">
<dt id="mlxtend.classifier.perceptron.Perceptron.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>init_weights=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/perceptron.html#Perceptron.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.perceptron.Perceptron.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit training data.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values.</dd>
<dt>shuffle <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>Shuffles training data every epoch if True to prevent circles.</dd>
<dt>init_weights <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: True)</span></dt>
<dd>Re-initializes weights prior to fitting. Set False to continue
training with weights from a previous fitting.</dd>
</dl>
<p>self : object</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.perceptron.Perceptron.net_input">
<code class="descname">net_input</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/perceptron.html#Perceptron.net_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.perceptron.Perceptron.net_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Net input function</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.perceptron.Perceptron.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/perceptron.html#Perceptron.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.perceptron.Perceptron.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>class <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Predicted class label.</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-mlxtend.classifier">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-mlxtend.classifier" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="mlxtend.classifier.Perceptron">
<em class="property">class </em><code class="descclassname">mlxtend.classifier.</code><code class="descname">Perceptron</code><span class="sig-paren">(</span><em>eta=0.1</em>, <em>epochs=50</em>, <em>shuffle=False</em>, <em>random_state=None</em>, <em>random_weights=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/perceptron.html#Perceptron"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.Perceptron" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Perceptron classifier.</p>
<dl class="docutils">
<dt>eta <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Learning rate (between 0.0 and 1.0)</dd>
<dt>epochs <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Passes over the training dataset.</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Random state for initializing random weights.</dd>
<dt>random_weights <span class="classifier-delimiter">:</span> <span class="classifier">list (default: [-0.5, 0.5])</span></dt>
<dd>Min and max values for initializing the random weights.
Initializes weights to 0 if None or False.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id19"><span class="problematic" id="id20">w_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">1d-array</span></dt>
<dd>Weights after fitting.</dd>
<dt><a href="#id21"><span class="problematic" id="id22">cost_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>Number of misclassifications in every epoch.</dd>
</dl>
<dl class="method">
<dt id="mlxtend.classifier.Perceptron.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>init_weights=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/perceptron.html#Perceptron.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.Perceptron.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit training data.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values.</dd>
<dt>shuffle <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>Shuffles training data every epoch if True to prevent circles.</dd>
<dt>init_weights <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: True)</span></dt>
<dd>Re-initializes weights prior to fitting. Set False to continue
training with weights from a previous fitting.</dd>
</dl>
<p>self : object</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.Perceptron.net_input">
<code class="descname">net_input</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/perceptron.html#Perceptron.net_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.Perceptron.net_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Net input function</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.Perceptron.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/perceptron.html#Perceptron.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.Perceptron.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>class <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Predicted class label.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mlxtend.classifier.Adaline">
<em class="property">class </em><code class="descclassname">mlxtend.classifier.</code><code class="descname">Adaline</code><span class="sig-paren">(</span><em>eta=0.01</em>, <em>epochs=50</em>, <em>learning='sgd'</em>, <em>random_seed=None</em>, <em>shuffle=False</em>, <em>zero_init_weight=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/adaline.html#Adaline"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.Adaline" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>ADAptive LInear NEuron classifier.</p>
<dl class="docutils">
<dt>eta <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Learning rate (between 0.0 and 1.0)</dd>
<dt>epochs <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Passes over the training dataset.</dd>
<dt>learning <span class="classifier-delimiter">:</span> <span class="classifier">str (default: sgd)</span></dt>
<dd>Gradient decent (gd) or stochastic gradient descent (sgd)</dd>
<dt>shuffle <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>Shuffles training data every epoch if True to prevent circles.</dd>
<dt>random_seed <span class="classifier-delimiter">:</span> <span class="classifier">int (default: None)</span></dt>
<dd>Set random state for shuffling and initializing the weights.</dd>
<dt>zero_init_weight <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>If True, weights are initialized to zero instead of small random
numbers in the interval [0,1]</dd>
</dl>
<dl class="docutils">
<dt><a href="#id23"><span class="problematic" id="id24">w_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">1d-array</span></dt>
<dd>Weights after fitting.</dd>
<dt><a href="#id25"><span class="problematic" id="id26">cost_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>Sum of squared errors after each epoch.</dd>
</dl>
<dl class="method">
<dt id="mlxtend.classifier.Adaline.activation">
<code class="descname">activation</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/adaline.html#Adaline.activation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.Adaline.activation" title="Permalink to this definition">¶</a></dt>
<dd><p>Activation function</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.Adaline.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>init_weights=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/adaline.html#Adaline.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.Adaline.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit training data.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values.</dd>
<dt>init_weights <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: True)</span></dt>
<dd>(Re)initializes weights to small random floats if True.</dd>
</dl>
<p>self : object</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.Adaline.net_input">
<code class="descname">net_input</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/adaline.html#Adaline.net_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.Adaline.net_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Net input function</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.Adaline.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/adaline.html#Adaline.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.Adaline.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>class <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Predicted class label.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mlxtend.classifier.LogisticRegression">
<em class="property">class </em><code class="descclassname">mlxtend.classifier.</code><code class="descname">LogisticRegression</code><span class="sig-paren">(</span><em>eta=0.01</em>, <em>epochs=50</em>, <em>regularization=None</em>, <em>l2_lambda=0.0</em>, <em>learning='sgd'</em>, <em>shuffle=False</em>, <em>random_seed=None</em>, <em>zero_init_weight=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/logistic_regression.html#LogisticRegression"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.LogisticRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Logistic regression classifier.</p>
<dl class="docutils">
<dt>eta <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Learning rate (between 0.0 and 1.0)</dd>
<dt>epochs <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Passes over the training dataset.</dd>
<dt>learning <span class="classifier-delimiter">:</span> <span class="classifier">str (default: sgd)</span></dt>
<dd>Learning rule, sgd (stochastic gradient descent)
or gd (gradient descent).</dd>
<dt>regularization <span class="classifier-delimiter">:</span> <span class="classifier">{None, &#8216;l2&#8217;} (default: None)</span></dt>
<dd>Type of regularization. No regularization if
<cite>regularization=None</cite>.</dd>
<dt>l2_lambda <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Regularization parameter for L2 regularization.
No regularization if l2_lambda=0.0.</dd>
<dt>shuffle <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>Shuffles training data every epoch if True to prevent circles.</dd>
<dt>random_seed <span class="classifier-delimiter">:</span> <span class="classifier">int (default: None)</span></dt>
<dd>Set random state for shuffling and initializing the weights.</dd>
<dt>zero_init_weight <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>If True, weights are initialized to zero instead of small random
numbers in the interval [0,1]</dd>
</dl>
<dl class="docutils">
<dt><a href="#id27"><span class="problematic" id="id28">w_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">1d-array</span></dt>
<dd>Weights after fitting.</dd>
<dt><a href="#id29"><span class="problematic" id="id30">cost_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>List of floats with sum of squared error cost (sgd or gd) for every
epoch.</dd>
</dl>
<dl class="method">
<dt id="mlxtend.classifier.LogisticRegression.activation">
<code class="descname">activation</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/logistic_regression.html#LogisticRegression.activation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.LogisticRegression.activation" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class probabilities for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<blockquote>
<div>Class 1 probability : float</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.LogisticRegression.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>init_weights=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/logistic_regression.html#LogisticRegression.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.LogisticRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit training data.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values.</dd>
<dt>init_weights <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: True)</span></dt>
<dd>(Re)initializes weights to small random floats if True.</dd>
</dl>
<p>self : object</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.LogisticRegression.net_input">
<code class="descname">net_input</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/logistic_regression.html#LogisticRegression.net_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.LogisticRegression.net_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Net input function.</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.LogisticRegression.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/logistic_regression.html#LogisticRegression.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.LogisticRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>class <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Predicted class label.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mlxtend.classifier.NeuralNetMLP">
<em class="property">class </em><code class="descclassname">mlxtend.classifier.</code><code class="descname">NeuralNetMLP</code><span class="sig-paren">(</span><em>n_output, n_features, n_hidden=30, l1=0.0, l2=0.0, epochs=500, eta=0.001, alpha=0.0, decrease_const=0.0, random_weights=[-1.0, 1.0], shuffle_init=True, shuffle_epoch=True, minibatches=1, random_state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/neuralnet_mlp.html#NeuralNetMLP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.NeuralNetMLP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Feedforward neural network / Multi-layer perceptron classifier.</p>
<dl class="docutils">
<dt>n_output <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Number of output units, should be equal to the
number of unique class labels.</dd>
<dt>n_features <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Number of features (dimensions) in the target dataset.
Should be equal to the number of columns in the X array.</dd>
<dt>n_hidden <span class="classifier-delimiter">:</span> <span class="classifier">int (default: 30)</span></dt>
<dd>Number of hidden units.</dd>
<dt>l1 <span class="classifier-delimiter">:</span> <span class="classifier">float (default: 0.0)</span></dt>
<dd>Lambda value for L1-regularization.
No regularization if l1=0.0 (default)</dd>
<dt>l2 <span class="classifier-delimiter">:</span> <span class="classifier">float (default: 0.0)</span></dt>
<dd>Lambda value for L2-regularization.
No regularization if l2=0.0 (default)</dd>
<dt>epochs <span class="classifier-delimiter">:</span> <span class="classifier">int (default: 500)</span></dt>
<dd>Number of passes over the training set.</dd>
<dt>eta <span class="classifier-delimiter">:</span> <span class="classifier">float (default: 0.001)</span></dt>
<dd>Learning rate.</dd>
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float (default: 0.0)</span></dt>
<dd>Momentum constant. Factor multiplied with the
gradient of the previous epoch t-1 to improve
learning speed
w(t) := w(t) - (grad(t) + alpha*grad(t-1))</dd>
<dt>decrease_const <span class="classifier-delimiter">:</span> <span class="classifier">float (default: 0.0)</span></dt>
<dd>Decrease constant. Shrinks the learning rate
after each epoch via eta / (1 + epoch*decrease_const)</dd>
<dt>random_weights <span class="classifier-delimiter">:</span> <span class="classifier">list (default: [-1.0, 1.0])</span></dt>
<dd>Min and max values for initializing the random weights.
Initializes weights to 0 if None or False.</dd>
<dt>shuffle_init <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: True)</span></dt>
<dd>Shuffles (a copy of the) training data before training.</dd>
<dt>shuffle_epoch <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: True)</span></dt>
<dd>Shuffles training data before every epoch if True to prevent circles.</dd>
<dt>minibatches <span class="classifier-delimiter">:</span> <span class="classifier">int (default: 1)</span></dt>
<dd>Divides training data into k minibatches for efficiency.
Normal gradient descent learning if k=1 (default).</dd>
<dt>random_state <span class="classifier-delimiter">:</span> <span class="classifier">int (default: None)</span></dt>
<dd>Set random state for shuffling and initializing the weights.</dd>
</dl>
<dl class="docutils">
<dt><a href="#id31"><span class="problematic" id="id32">cost_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>Sum of squared errors after each epoch.</dd>
</dl>
<dl class="method">
<dt id="mlxtend.classifier.NeuralNetMLP.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>print_progress=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/neuralnet_mlp.html#NeuralNetMLP.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.NeuralNetMLP.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Learn weights from training data.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = [n_samples, n_features]</span></dt>
<dd>Input layer with original features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = [n_samples]</span></dt>
<dd>Target class labels.</dd>
<dt>print_progress <span class="classifier-delimiter">:</span> <span class="classifier">bool (default: False)</span></dt>
<dd>Prints progress as the number of epochs
to stderr.</dd>
</dl>
<p>self</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.NeuralNetMLP.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/neuralnet_mlp.html#NeuralNetMLP.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.NeuralNetMLP.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = [n_samples, n_features]</span></dt>
<dd>Input layer with original features.</dd>
</dl>
<dl class="docutils">
<dt>y_pred <span class="classifier-delimiter">:</span> <span class="classifier">array, shape = [n_samples]</span></dt>
<dd>Predicted class labels.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mlxtend.classifier.EnsembleClassifier">
<em class="property">class </em><code class="descclassname">mlxtend.classifier.</code><code class="descname">EnsembleClassifier</code><span class="sig-paren">(</span><em>clfs</em>, <em>voting='hard'</em>, <em>weights=None</em>, <em>verbose=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.EnsembleClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.BaseEstimator</span></code>, <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.ClassifierMixin</span></code>, <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.TransformerMixin</span></code></p>
<p>Soft Voting/Majority Rule classifier for unfitted clfs.</p>
<dl class="docutils">
<dt>clfs <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_classifiers]</span></dt>
<dd>A list of classifiers.
Invoking the <cite>fit</cite> method on the <cite>VotingClassifier</cite> will fit clones
of those original classifiers that will be stored in the class attribute
<cite>self.clfs_</cite>.</dd>
<dt>voting <span class="classifier-delimiter">:</span> <span class="classifier">str, {&#8216;hard&#8217;, &#8216;soft&#8217;} (default=&#8217;hard&#8217;)</span></dt>
<dd>If &#8216;hard&#8217;, uses predicted class labels for majority rule voting.
Else if &#8216;soft&#8217;, predicts the class label based on the argmax of
the sums of the predicted probalities, which is recommended for
an ensemble of well-calibrated classifiers.</dd>
<dt>weights <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_classifiers], optional (default=`None`)</span></dt>
<dd>Sequence of weights (<cite>float</cite> or <cite>int</cite>) to weight the occurances of
predicted class labels (<cite>hard</cite> voting) or class probabilities
before averaging (<cite>soft</cite> voting). Uses uniform weights if <cite>None</cite>.</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">int, optional (default=0)</span></dt>
<dd><dl class="first last docutils">
<dt>Controls the verbosity of the building process.</dt>
<dd><p class="first"><cite>verbose=0</cite> (default): Prints nothing
<cite>verbose=1</cite>: Prints the number &amp; name of the clf being fitted
<cite>verbose=2</cite>: Prints info about the parameters of the clf being fitted
<cite>verbose&gt;2</cite>: Changes <cite>verbose</cite> param of the underlying clf to</p>
<blockquote class="last">
<div>self.verbose - 2</div></blockquote>
</dd>
</dl>
</dd>
</dl>
<p><a href="#id33"><span class="problematic" id="id34">classes_</span></a> : array-like, shape = [n_predictions]</p>
<dl class="docutils">
<dt>clf <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_predictions]</span></dt>
<dd>The unmodified input classifiers</dd>
<dt><a href="#id35"><span class="problematic" id="id36">clf_</span></a> <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_predictions]</span></dt>
<dd>Fitted clones of the input classifiers</dd>
</dl>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mlxtend.sklearn</span> <span class="kn">import</span> <span class="n">EnsembleClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf3</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf1</span> <span class="o">=</span> <span class="n">EnsembleClassifier</span><span class="p">(</span><span class="n">clfs</span><span class="o">=</span><span class="p">[</span><span class="n">clf1</span><span class="p">,</span> <span class="n">clf2</span><span class="p">,</span> <span class="n">clf3</span><span class="p">],</span>
<span class="gp">... </span><span class="n">voting</span><span class="o">=</span><span class="s">&#39;hard&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf1</span> <span class="o">=</span> <span class="n">eclf1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">eclf1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="go">[1 1 1 2 2 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf2</span> <span class="o">=</span> <span class="n">EnsembleClassifier</span><span class="p">(</span><span class="n">clfs</span><span class="o">=</span><span class="p">[</span><span class="n">clf1</span><span class="p">,</span> <span class="n">clf2</span><span class="p">,</span> <span class="n">clf3</span><span class="p">],</span> <span class="n">voting</span><span class="o">=</span><span class="s">&#39;soft&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf2</span> <span class="o">=</span> <span class="n">eclf2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">eclf2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="go">[1 1 1 2 2 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf3</span> <span class="o">=</span> <span class="n">EnsembleClassifier</span><span class="p">(</span><span class="n">clfs</span><span class="o">=</span><span class="p">[</span><span class="n">clf1</span><span class="p">,</span> <span class="n">clf2</span><span class="p">,</span> <span class="n">clf3</span><span class="p">],</span>
<span class="gp">... </span>                         <span class="n">voting</span><span class="o">=</span><span class="s">&#39;soft&#39;</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eclf3</span> <span class="o">=</span> <span class="n">eclf3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">eclf3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="go">[1 1 1 2 2 2]</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
<dl class="method">
<dt id="mlxtend.classifier.EnsembleClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.EnsembleClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the clfs.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Target values.</dd>
</dl>
<p>self : object</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.EnsembleClassifier.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier.get_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.EnsembleClassifier.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Return estimator parameter names for GridSearch support</p>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.EnsembleClassifier.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.EnsembleClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>maj <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples]</span></dt>
<dd>Predicted class labels.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.EnsembleClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.EnsembleClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class probabilities for X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>avg <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples, n_classes]</span></dt>
<dd>Weighted average probability for each class per sample.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mlxtend.classifier.EnsembleClassifier.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/mlxtend/classifier/ensemble.html#EnsembleClassifier.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mlxtend.classifier.EnsembleClassifier.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Return class labels or probabilities for X for each estimator.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt>
<dd>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</dd>
</dl>
<dl class="docutils">
<dt>If <cite>voting=&#8217;soft&#8217;</cite>:</dt>
<dd><dl class="first last docutils">
<dt>array-like = [n_classifiers, n_samples, n_classes]</dt>
<dd>Class probabilties calculated by each classifier.</dd>
</dl>
</dd>
<dt>If <cite>voting=&#8217;hard&#8217;</cite>:</dt>
<dd><dl class="first last docutils">
<dt>array-like = [n_classifiers, n_samples]</dt>
<dd>Class labels predicted by each classifier.</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">mlxtend.classifier package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-mlxtend.classifier.adaline">mlxtend.classifier.adaline module</a></li>
<li><a class="reference internal" href="#module-mlxtend.classifier.ensemble">mlxtend.classifier.ensemble module</a></li>
<li><a class="reference internal" href="#module-mlxtend.classifier.logistic_regression">mlxtend.classifier.logistic_regression module</a></li>
<li><a class="reference internal" href="#module-mlxtend.classifier.neuralnet_mlp">mlxtend.classifier.neuralnet_mlp module</a></li>
<li><a class="reference internal" href="#module-mlxtend.classifier.perceptron">mlxtend.classifier.perceptron module</a></li>
<li><a class="reference internal" href="#module-mlxtend.classifier">Module contents</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/bla/mlxtend.classifier.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2015, Author.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.3.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.6</a>
      
      |
      <a href="../_sources/bla/mlxtend.classifier.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>