<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
    <meta name="author" content="Sebastian Raschka"> 
    <link rel="canonical" href="http://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization/"> 
    <link rel="shortcut icon" href="../../../../../../favicon.ico">

    <title>Gradient optimization - mlxtend</title>

    <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../../css/base.css" rel="stylesheet">
    <link href="../../../css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../css/highlight.css">


    <link href="../../../extra.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-38457794-2', 'rasbt.github.io/mlxtend/');
    ga('send', 'pageview');
    </script>
    
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->
            <a class="navbar-brand" href="../../..">mlxtend</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">classifier</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../classifier/EnsembleVoteClassifier/">EnsembleVoteClassifier</a>
</li>

        
            
<li >
    <a href="../../classifier/Perceptron/">Perceptron</a>
</li>

        
            
<li >
    <a href="../../classifier/Adaline/">Adaline</a>
</li>

        
            
<li >
    <a href="../../classifier/LogisticRegression/">LogisticRegression</a>
</li>

        
            
<li >
    <a href="../../classifier/NeuralNetMLP/">NeuralNetMLP</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regressor</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regressor/LinearRegression/">LinearRegression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regression_utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regression_utils/plot_linear_regression/">Plot linear regression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_selection</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_selection/SequentialFeatureSelector/">SequentialFeatureSelector</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">evaluate</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../evaluate/confusion_matrix/">Confusion matrix</a>
</li>

        
            
<li >
    <a href="../../evaluate/plot_decision_regions/">Plot decision regions</a>
</li>

        
            
<li >
    <a href="../../evaluate/plot_learning_curves/">Plot learning curves</a>
</li>

        
            
<li >
    <a href="../../evaluate/scoring/">Scoring</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">preprocessing</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../preprocessing/DenseTransformer/">DenseTransformer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/MeanCenterer/">MeanCenterer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/minmax_scaling/">Minmax scaling</a>
</li>

        
            
<li >
    <a href="../../preprocessing/shuffle_arrays_unison/">Shuffle arrays unison</a>
</li>

        
            
<li >
    <a href="../../preprocessing/standardize/">Standardize</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">data</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../data/autompg_data/">Autompg data</a>
</li>

        
            
<li >
    <a href="../../data/boston_housing_data/">Boston housing data</a>
</li>

        
            
<li >
    <a href="../../data/iris_data/">Iris data</a>
</li>

        
            
<li >
    <a href="../../data/mnist_data/">Mnist data</a>
</li>

        
            
<li >
    <a href="../../data/load_mnist/">Load mnist</a>
</li>

        
            
<li >
    <a href="../../data/wine_data/">Wine data</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">file_io</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../file_io/find_filegroups/">Find filegroups</a>
</li>

        
            
<li >
    <a href="../../file_io/find_files/">Find files</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general plotting</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../general_plotting/category_scatter/">Category scatter</a>
</li>

        
            
<li >
    <a href="../../general_plotting/enrichment_plot/">Enrichment plot</a>
</li>

        
            
<li >
    <a href="../../general_plotting/stacked_barplot/">Stacked barplot</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">math</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../math/num_combinations/">Num combinations</a>
</li>

        
            
<li >
    <a href="../../math/num_permutations/">Num permutations</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">text</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../text/generalize_names/">Generalize names</a>
</li>

        
            
<li >
    <a href="../../text/generalize_names_duplcheck/">Generalize names duplcheck</a>
</li>

        
            
<li >
    <a href="../../text/tokenizer/">Tokenizer</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../utils/Counter/">Counter</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general concepts</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../activation-functions/">Activation functions</a>
</li>

        
            
<li class="active">
    <a href="./">Gradient optimization</a>
</li>

        
            
<li >
    <a href="../linear-gradient-derivative/">Linear gradient derivative</a>
</li>

        
            
<li >
    <a href="../regularization-linear/">Regularization linear</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">Upcoming Features / 0.3.1dev</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../tf_classifier/TfSoftmaxRegression/">TfSoftmaxRegression</a>
</li>

        
            
<li >
    <a href="../../classifier/SoftmaxRegression/">SoftmaxRegression</a>
</li>

        
            
<li >
    <a href="../../regressor/StackingRegressor/">StackingRegressor</a>
</li>

        
            
<li >
    <a href="../../classifier/StackingClassifier/">StackingClassifier</a>
</li>

        
            
<li >
    <a href="../../preprocessing/one-hot_encoding/">One hot encoding</a>
</li>

        
    </ul>
  </li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.classifier/">Mlxtend.classifier</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.data/">Mlxtend.data</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.evaluate/">Mlxtend.evaluate</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.feature_selection/">Mlxtend.feature selection</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.file_io/">Mlxtend.file io</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.general_plotting/">Mlxtend.general plotting</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.preprocessing/">Mlxtend.preprocessing</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regression_utils/">Mlxtend.regression utils</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regressor/">Mlxtend.regressor</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.text/">Mlxtend.text</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.utils/">Mlxtend.utils</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../../../installation/">Installation</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../changelog/">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../../../contributing/">Contributing</a>
</li>

                        
                            
<li >
    <a href="../../../license/">License</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>
            

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                
                    <li >
                        <a rel="next" href="../activation-functions/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../linear-gradient-derivative/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                
                
                    <li>
                        <a href="https://github.com/rasbt/mlxtend">
                            
                                <i class="fa fa-github"></i>
                            
                            GitHub
                        </a>
                    </li>
                
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#gradient-descent-and-stochastic-gradient-descent">Gradient Descent and Stochastic Gradient Descent</a></li>
        
            <li><a href="#gradient-descent-gd-optimization">Gradient Descent (GD) Optimization</a></li>
        
            <li><a href="#stochastic-gradient-descent-sgd">Stochastic Gradient Descent (SGD)</a></li>
        
            <li><a href="#mini-batch-gradient-descent-mb-gd">Mini-Batch Gradient Descent (MB-GD)</a></li>
        
            <li><a href="#learning-rates">Learning Rates</a></li>
        
    
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="gradient-descent-and-stochastic-gradient-descent">Gradient Descent and Stochastic Gradient Descent</h1>
<h2 id="gradient-descent-gd-optimization">Gradient Descent (GD) Optimization</h2>
<p>Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each epoch (= pass over the training dataset).</p>
<p>Compatible cost functions <mathjax>$J(\cdot)$</mathjax></p>
<ul>
<li>
<p>Sum of squared errors (SSE) [ <a href="../regressor/linear_regression.html">mlxtend.regressor.LinearRegression</a>, <a href="../classifier/adaline.html">mlxtend.classfier.Adaline</a> ]:
<mathjax>$$J(\mathbf{w}) = \frac{1}{2} \sum_i (\text{target}^{(i)} - \text{output}^{(i)})^2$$</mathjax></p>
</li>
<li>
<p>Logistic Cost (cross-entropy) [ <a href="../classifier/logisitic_regression.html">mlxtend.classfier.LogisticRegression</a> ]:
...</p>
</li>
</ul>
<p>The magnitude and direction of the weight update is computed by taking a step in the opposite direction of the cost gradient</p>
<p><mathjax>$$\Delta w_j = -\eta \frac{\partial J}{\partial w_j},$$</mathjax></p>
<p>where <mathjax>$\eta$</mathjax> is the learning rate. The weights are then updated after each epoch via the following update rule:</p>
<p><mathjax>$$\mathbf{w} := \mathbf{w} + \Delta\mathbf{w},$$</mathjax></p>
<p>where <mathjax>$\Delta\mathbf{w}$</mathjax> is a vector that contains the weight updates of each weight coefficient <mathjax>${w}$</mathjax>, which are computed as follows:</p>
<p><mathjax>$$\Delta w_j = -\eta \frac{\partial J}{\partial w_j}\\
= -\eta \sum_i (\text{target}^{(i)} - \text{output}^{(i)})(-x_{j}^{(i)})\\
= \eta \sum_i (\text{target}^{(i)} - \text{output}^{(i)})x_{j}^{(i)}.$$</mathjax></p>
<p>Essentially, we can picture Gradient Descent optimization as a hiker (the weight coefficient) who wants to climb down a mountain (cost function) into valley (cost minimum), and each step is determined by the steepness of the slope (gradient) and the leg length of the hiker (learning rate). Considering a cost function with only a single weight coefficient, we can illustrate this concept as follows:</p>
<p><img alt="" src="../gradient-optimization_files/ball.png" /></p>
<h2 id="stochastic-gradient-descent-sgd">Stochastic Gradient Descent (SGD)</h2>
<p>In Gradient Descent optimization, we compute the cost gradient based on the complete training set; hence, we sometimes also call it <em>batch gradient descent</em>. In case of very large datasets, using Gradient Descent can be quite costly since we are only taking a single step for one pass over the training set -- thus, the larger the training set, the slower our algorithm updates the weights and the longer it may take until it converges to the global cost minimum (note that the SSE cost function is convex).</p>
<p>In Stochastic Gradient Descent (sometimes also referred to as <em>iterative</em> or <em>on-line</em> gradient descent), we <strong>don't</strong> accumulate the weight updates as we've seen above for Gradient Descent:</p>
<ul>
<li>for one or more epochs:<ul>
<li>for each weight <mathjax>$j$</mathjax><ul>
<li><mathjax>$w_j := w + \Delta w_j$</mathjax>,   where:   <mathjax>$\Delta w_j= \eta \sum_i (\text{target}^{(i)} - \text{output}^{(i)})x_{j}^{(i)}$</mathjax></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Instead, we update the weights after each training sample:</p>
<ul>
<li>for one or more epochs, or until approx. cost minimum is reached:<ul>
<li>for training sample <mathjax>$i$</mathjax>:<ul>
<li>for each weight <mathjax>$j$</mathjax><ul>
<li><mathjax>$w_j := w + \Delta w_j$</mathjax>,   where:   <mathjax>$\Delta w_j= \eta (\text{target}^{(i)} - \text{output}^{(i)})x_{j}^{(i)}$</mathjax></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Here, the term "stochastic" comes from the fact that the gradient based on a single training sample is a "stochastic approximation" of the "true" cost gradient. Due to its stochastic nature, the path towards the global cost minimum is not "direct" as in Gradient Descent, but may go "zig-zag" if we are visuallizing the cost surface in a 2D space. However, it has been shown that Stochastic Gradient Descent almost surely converges to the global cost minimum if the cost function is convex (or pseudo-convex)[1].</p>
<h3 id="stochastic-gradient-descent-shuffling">Stochastic Gradient Descent Shuffling</h3>
<p>There are several different flavors of stochastic gradient descent, which can be all seen throughout the literature. Let's take a look at the three most common variants:</p>
<h4 id="a">A)</h4>
<ul>
<li>randomly shuffle samples in the training set<ul>
<li>for one or more epochs, or until approx. cost minimum is reached<ul>
<li>for training sample <em>i</em><ul>
<li>compute gradients and perform weight updates</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="b">B)</h4>
<ul>
<li>for one or more epochs, or until approx. cost minimum is reached<ul>
<li>randomly shuffle samples in the training set<ul>
<li>for training sample <em>i</em><ul>
<li>compute gradients and perform weight updates</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="c">C)</h4>
<ul>
<li>for iterations <em>t</em>, or until approx. cost minimum is reached:<ul>
<li>draw random sample from the training set<ul>
<li>compute gradients and perform weight updates</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>In scenario A [3], we shuffle the training set only one time in the beginning; whereas in scenario B, we shuffle the training set after each epoch to prevent repeating update cycles. In both scenario A and scenario B, each training sample is only used once per epoch to update the model weights.</p>
<p>In scenario C, we draw the training samples randomly with replacement from the training set [2]. If the number of iterations <em>t</em> is equal to the number of training samples, we learn the model based on a <em>bootstrap sample</em> of the training set.</p>
<h2 id="mini-batch-gradient-descent-mb-gd">Mini-Batch Gradient Descent (MB-GD)</h2>
<p>Mini-Batch Gradient Descent (MB-GD) a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all <em>n</em> training samples (GD), we compute the gradient from <mathjax>$1 &lt; k &lt; n$</mathjax> training samples (a common mini-batch size is <mathjax>$k=50$</mathjax>).</p>
<p>MB-GD converges in fewer iterations than GD because we update the weights more frequently; however, MB-GD let's us utilize vectorized operation, which typically results in a computational performance gain over SGD.</p>
<h2 id="learning-rates">Learning Rates</h2>
<ul>
<li>
<p>An adaptive learning rate <mathjax>$\eta$</mathjax>: Choosing a decrease constant <em>d</em> that shrinks the learning rate over time:  <mathjax>$\eta(t+1) := \eta(t) / (1 + t \times d)$</mathjax></p>
</li>
<li>
<p>Momentum learning by adding a factor of the previous gradient to the weight update for faster updates: <mathjax>$\Delta \mathbf{w}_{t+1} := \eta \nabla J(\mathbf{w}_{t+1}) + \alpha \Delta {w}_{t}$</mathjax></p>
</li>
</ul>
<h3 id="references">References</h3>
<ul>
<li>[1] Bottou, Léon (1998). <em>"Online Algorithms and Stochastic Approximations"</em>. Online Learning and Neural Networks. Cambridge University Press. ISBN 978-0-521-65263-6</li>
<li>[2] Bottou, Léon. <em>"Large-scale machine learning with stochastic gradient descent."</em> Proceedings of COMPSTAT'2010. Physica-Verlag HD, 2010. 177-186.</li>
<li>[3] Bottou, Léon. <em>"Stochastic gradient descent tricks."</em> Neural Networks: Tricks of the Trade. Springer Berlin Heidelberg, 2012. 421-436.</li>
</ul></div>
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Copyright &copy; 2014-2016 <a href="http://sebastianraschka.com">Sebastian Raschka</a><br></small>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="../../../js/jquery-1.10.2.min.js"></script>
    <script src="../../../js/bootstrap-3.0.3.min.js"></script>
    <script src="../../../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '../../..';
    </script>
    <script data-main="../../../mkdocs/js/search.js" src="../../../mkdocs/js/require.js"></script>
    <script src="../../../js/base.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script src="../../../mathjaxhelper.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>
