<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
    <meta name="author" content="Sebastian Raschka"> 
    <link rel="canonical" href="http://rasbt.github.io/mlxtend/user_guide/tf_classifier/TfMultiLayerPerceptron/"> 
    <link rel="shortcut icon" href="../../../../../../favicon.ico">

    <title>TfMultiLayerPerceptron - mlxtend</title>

    <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../../css/base.css" rel="stylesheet">
    <link href="../../../css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../css/highlight.css">


    <link href="../../../extra.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-38457794-2', 'rasbt.github.io/mlxtend/');
    ga('send', 'pageview');
    </script>
    
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->
            <a class="navbar-brand" href="../../..">mlxtend</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../USER_GUIDE_INDEX/">USER GUIDE INDEX</a>
</li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">classifier</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../classifier/EnsembleVoteClassifier/">EnsembleVoteClassifier</a>
</li>

        
            
<li >
    <a href="../../classifier/StackingClassifier/">StackingClassifier</a>
</li>

        
            
<li >
    <a href="../../classifier/Perceptron/">Perceptron</a>
</li>

        
            
<li >
    <a href="../../classifier/Adaline/">Adaline</a>
</li>

        
            
<li >
    <a href="../../classifier/LogisticRegression/">LogisticRegression</a>
</li>

        
            
<li >
    <a href="../../classifier/SoftmaxRegression/">SoftmaxRegression</a>
</li>

        
            
<li >
    <a href="../../classifier/NeuralNetMLP/">NeuralNetMLP</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">tf_classifier</a>
    <ul class="dropdown-menu">
        
            
<li class="active">
    <a href="./">TfMultiLayerPerceptron</a>
</li>

        
            
<li >
    <a href="../TfSoftmaxRegression/">TfSoftmaxRegression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regressor</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regressor/LinearRegression/">LinearRegression</a>
</li>

        
            
<li >
    <a href="../../regressor/StackingRegressor/">StackingRegressor</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regression_utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regression_utils/plot_linear_regression/">Plot linear regression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_selection</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_selection/SequentialFeatureSelector/">SequentialFeatureSelector</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_extraction</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_extraction/PrincipalComponentAnalysis/">PrincipalComponentAnalysis</a>
</li>

        
            
<li >
    <a href="../../feature_extraction/LinearDiscriminantAnalysis/">LinearDiscriminantAnalysis</a>
</li>

        
            
<li >
    <a href="../../feature_extraction/RBFKernelPCA/">RBFKernelPCA</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">evaluate</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../evaluate/confusion_matrix/">Confusion matrix</a>
</li>

        
            
<li >
    <a href="../../evaluate/plot_decision_regions/">Plot decision regions</a>
</li>

        
            
<li >
    <a href="../../evaluate/plot_learning_curves/">Plot learning curves</a>
</li>

        
            
<li >
    <a href="../../evaluate/scoring/">Scoring</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">preprocessing</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../preprocessing/DenseTransformer/">DenseTransformer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/MeanCenterer/">MeanCenterer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/minmax_scaling/">Minmax scaling</a>
</li>

        
            
<li >
    <a href="../../preprocessing/shuffle_arrays_unison/">Shuffle arrays unison</a>
</li>

        
            
<li >
    <a href="../../preprocessing/standardize/">Standardize</a>
</li>

        
            
<li >
    <a href="../../preprocessing/one-hot_encoding/">One hot encoding</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">data</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../data/autompg_data/">Autompg data</a>
</li>

        
            
<li >
    <a href="../../data/boston_housing_data/">Boston housing data</a>
</li>

        
            
<li >
    <a href="../../data/iris_data/">Iris data</a>
</li>

        
            
<li >
    <a href="../../data/mnist_data/">Mnist data</a>
</li>

        
            
<li >
    <a href="../../data/load_mnist/">Load mnist</a>
</li>

        
            
<li >
    <a href="../../data/wine_data/">Wine data</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">file_io</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../file_io/find_filegroups/">Find filegroups</a>
</li>

        
            
<li >
    <a href="../../file_io/find_files/">Find files</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general plotting</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../general_plotting/category_scatter/">Category scatter</a>
</li>

        
            
<li >
    <a href="../../general_plotting/enrichment_plot/">Enrichment plot</a>
</li>

        
            
<li >
    <a href="../../general_plotting/stacked_barplot/">Stacked barplot</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">math</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../math/num_combinations/">Num combinations</a>
</li>

        
            
<li >
    <a href="../../math/num_permutations/">Num permutations</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">text</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../text/generalize_names/">Generalize names</a>
</li>

        
            
<li >
    <a href="../../text/generalize_names_duplcheck/">Generalize names duplcheck</a>
</li>

        
            
<li >
    <a href="../../text/tokenizer/">Tokenizer</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../utils/Counter/">Counter</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general concepts</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../general_concepts/activation-functions/">Activation functions</a>
</li>

        
            
<li >
    <a href="../../general_concepts/gradient-optimization/">Gradient optimization</a>
</li>

        
            
<li >
    <a href="../../general_concepts/linear-gradient-derivative/">Linear gradient derivative</a>
</li>

        
            
<li >
    <a href="../../general_concepts/regularization-linear/">Regularization linear</a>
</li>

        
    </ul>
  </li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.classifier/">Mlxtend.classifier</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.tf_classifier/">Mlxtend.tf classifier</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.data/">Mlxtend.data</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.evaluate/">Mlxtend.evaluate</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.feature_selection/">Mlxtend.feature selection</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.file_io/">Mlxtend.file io</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.general_plotting/">Mlxtend.general plotting</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.preprocessing/">Mlxtend.preprocessing</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regression_utils/">Mlxtend.regression utils</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regressor/">Mlxtend.regressor</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.text/">Mlxtend.text</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.utils/">Mlxtend.utils</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../../../installation/">Installation</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../changelog/">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../../../contributing/">How To Contribute</a>
</li>

                        
                            
<li >
    <a href="../../../contributors/">Contributors</a>
</li>

                        
                            
<li >
    <a href="../../../license/">License</a>
</li>

                        
                            
<li >
    <a href="../../../cite/">Citing Mlxtend</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>
            

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                
                    <li >
                        <a rel="next" href="../../classifier/NeuralNetMLP/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../TfSoftmaxRegression/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                
                
                    <li>
                        <a href="https://github.com/rasbt/mlxtend">
                            
                                <i class="fa fa-github"></i>
                            
                            GitHub
                        </a>
                    </li>
                
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#tensorflow-multi-layer-perceptron">TensorFlow Multi-Layer Perceptron</a></li>
        
    
        <li class="main "><a href="#overview">Overview</a></li>
        
            <li><a href="#references">References</a></li>
        
    
        <li class="main "><a href="#examples">Examples</a></li>
        
            <li><a href="#example-1-gradient-descent">Example 1 - Gradient Descent</a></li>
        
            <li><a href="#example-2-stochastic-gradient-descent">Example 2 - Stochastic Gradient Descent</a></li>
        
            <li><a href="#example-3-mnist">Example 3 - MNIST</a></li>
        
            <li><a href="#example-4-training-and-validation-accuracies-during-training">Example 4 -- Training and Validation Accuracies During Training</a></li>
        
            <li><a href="#example-5-dropout">Example 5 -- Dropout</a></li>
        
    
        <li class="main "><a href="#api">API</a></li>
        
            <li><a href="#methods">Methods</a></li>
        
    
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="tensorflow-multi-layer-perceptron">TensorFlow Multi-Layer Perceptron</h1>
<p>A multi-layer perceptron class for binary and multi-class classification tasks.</p>
<blockquote>
<p>from mlxtend.tf_classifier import TfMultiLayerPerceptron</p>
</blockquote>
<h1 id="overview">Overview</h1>
<p>(A more detailed tutorial on multi-layer perceptrons is in preparation.)</p>
<p><img alt="" src="../TfMultiLayerPerceptron_files/mlp_overview_1.png" /></p>
<p><img alt="" src="../TfMultiLayerPerceptron_files/mlp_overview_2.png" /></p>
<p>Please also see the activation function cheatsheet at <a href="../../general_concepts/activation-functions/"><code>general_concepts.activation-functions</code></a>.</p>
<h3 id="references">References</h3>
<ul>
<li>Srivastava, Nitish, et al. <a href="http://dl.acm.org/citation.cfm?id=2670313"><em>"Dropout: A simple way to prevent neural networks from overfitting."</em></a> The Journal of Machine Learning Research 15.1 (2014): 1929-1958.</li>
</ul>
<h1 id="examples">Examples</h1>
<h2 id="example-1-gradient-descent">Example 1 - Gradient Descent</h2>
<p>Each integer in the <code>hidden_layers</code> list argument specifies the number of neurons for the respective layer; via the <code>activations</code>, we specify the activation functions for the individual hidden layer. Below, we initialize a multi-layer perceptron with 1 hidden layer using the logistic sigmoid activation. Furthermore, we train the network via simple gradient descent training by setting <code>optimizer='gradientdescent'</code> and <code>minibatches=1</code>. </p>
<pre><code class="python">from mlxtend.tf_classifier import TfMultiLayerPerceptron
from mlxtend.data import iris_data
from mlxtend.evaluate import plot_decision_regions
import matplotlib.pyplot as plt

# Loading Data
X, y = iris_data()
X = X[:, [0, 3]] # sepal length and petal width

# standardize
X[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()
X[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()

mlp = TfMultiLayerPerceptron(eta=0.5, 
                             epochs=20, 
                             hidden_layers=[10],
                             activations=['logistic'],
                             optimizer='gradientdescent',
                             print_progress=True, 
                             minibatches=1, 
                             random_seed=1)

mlp.fit(X, y)

plt.plot(range(len(mlp.cost_)), mlp.cost_)
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.show()
</code></pre>

<pre><code>Epoch: 20/20 | Cost 0.55 | TrainAcc 0.83
</code></pre>
<p><img alt="png" src="../TfMultiLayerPerceptron_files/TfMultiLayerPerceptron_15_1.png" /></p>
<p>Continue the training if cost could be further decreased via additional epochs. Instead of training the classifier another 20 epochs, we modify the epochs and set them to 550. Also, we want to make sure to set <code>init_weights</code> to <code>False</code> in order to re-use the model parameters from the previous training.</p>
<pre><code class="python">mlp.epochs = 550
mlp.fit(X, y, init_weights=False)
plt.plot(range(len(mlp.cost_)), mlp.cost_)
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.show()
</code></pre>

<pre><code>Epoch: 550/550 | Cost 0.12 | TrainAcc 0.96
</code></pre>
<p><img alt="png" src="../TfMultiLayerPerceptron_files/TfMultiLayerPerceptron_17_1.png" /></p>
<pre><code class="python">plot_decision_regions(X=X, y=y, clf=mlp)
plt.title('Logistic Sigmoid MLP - Gradient Descent')
plt.show()
</code></pre>

<p><img alt="png" src="../TfMultiLayerPerceptron_files/TfMultiLayerPerceptron_18_0.png" /></p>
<h3 id="predicting-class-labels">Predicting Class Labels</h3>
<pre><code class="python">print('Predicted class labels:', mlp.predict(X[[0, 99, 149]]))
</code></pre>

<pre><code>Predicted class labels: [0 1 2]
</code></pre>
<h3 id="predicting-class-probabilities">Predicting Class Probabilities</h3>
<pre><code class="python">print('Predicted class probabilities:\n', mlp.predict_proba(X[[0, 99, 149]]))
</code></pre>

<pre><code>Predicted class probabilities:
 [[  9.92696404e-01   7.30253477e-03   1.04788933e-06]
 [  1.58569030e-03   9.77745533e-01   2.06688400e-02]
 [  5.52368738e-06   1.68280467e-01   8.31713974e-01]]
</code></pre>
<h2 id="example-2-stochastic-gradient-descent">Example 2 - Stochastic Gradient Descent</h2>
<p>Stochastic gradient descent training sample by sample can be achieved by setting the number of minibatches equal to the number of samples in the training dataset; everything between <code>minibatches=1</code> and <code>minibatches=len(y)</code> is "minibatch" stochastic gradient descent. Below, we train a network using 10 minibatches.</p>
<pre><code class="python">from mlxtend.data import iris_data
from mlxtend.evaluate import plot_decision_regions
from mlxtend.tf_classifier import TfMultiLayerPerceptron
import matplotlib.pyplot as plt

# Loading Data

X, y = iris_data()
X = X[:, [0, 3]] # sepal length and petal width

# standardize
X[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()
X[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()

mlp = TfMultiLayerPerceptron(eta=0.5, 
                             epochs=100, 
                             hidden_layers=[10],
                             activations=['logistic'],
                             print_progress=True, 
                             optimizer='gradientdescent',
                             minibatches=10, 
                             random_seed=1)

mlp.fit(X, y)

plt.plot(range(len(mlp.cost_)), mlp.cost_)
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.show()

plot_decision_regions(X, y, clf=mlp)
plt.title('MLP - Minibatch Stochastic Gradient Descent')
plt.show()
</code></pre>

<pre><code>Epoch: 100/100 | Cost 0.13 | TrainAcc 0.95
</code></pre>
<p><img alt="png" src="../TfMultiLayerPerceptron_files/TfMultiLayerPerceptron_25_1.png" /></p>
<p><img alt="png" src="../TfMultiLayerPerceptron_files/TfMultiLayerPerceptron_25_2.png" /></p>
<h2 id="example-3-mnist">Example 3 - MNIST</h2>
<p>Please note that <code>mnist_data</code> just contains a random 5000-sample subset of MNIST (~10% of the original dataset size) suitable for demonstration purposes regarding computational efficiency.</p>
<p>Although it may be overkill, and the network may terribly overfit the training data, let us initialize a more complex neural network with 2 hidden layers and 200 ReLU (Rectifier Linear Units) each.</p>
<pre><code class="python">from mlxtend.data import mnist_data
from mlxtend.tf_classifier import TfMultiLayerPerceptron
import matplotlib.pyplot as plt

X, y = mnist_data()

mlp = TfMultiLayerPerceptron(eta=0.01, 
                             epochs=30, 
                             hidden_layers=[200, 200],
                             activations=['relu', 'relu'],
                             print_progress=1, 
                             minibatches=5, 
                             optimizer='adam',
                             random_seed=1)

mlp.fit(X, y)

plt.plot(range(len(mlp.cost_)), mlp.cost_)
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.show()
</code></pre>

<pre><code>Epoch: 30/30 | Cost 0.02 | TrainAcc 1.00
</code></pre>
<p><img alt="png" src="../TfMultiLayerPerceptron_files/TfMultiLayerPerceptron_29_1.png" /></p>
<pre><code class="python">import numpy as np
y_pred = mlp.predict(X)
print('Training Accuracy: %.2f%%' % (mlp.score(X, y) * 100))
</code></pre>

<pre><code>Training Accuracy: 100.00%
</code></pre>
<pre><code class="python">def plot_digit(X, y, idx):
    img = X[idx].reshape(28,28)
    plt.imshow(img, cmap='Greys',  interpolation='nearest')
    plt.title('true label: %d' % y[idx])
    plt.show()
plot_digit(X, y, 4999)  
</code></pre>

<p><img alt="png" src="../TfMultiLayerPerceptron_files/TfMultiLayerPerceptron_31_0.png" /></p>
<pre><code class="python">print('Prediction: %d' % mlp.predict(X[4999, None]))
</code></pre>

<pre><code>Prediction: 9
</code></pre>
<h2 id="example-4-training-and-validation-accuracies-during-training">Example 4 -- Training and Validation Accuracies During Training</h2>
<p>Training accuracies are collected for each epoch by default. Optionally, we can pass validation dataset during model fitting to compute the validation accuracy values for each epoch. Here, pass 4000 samples from MNIST for training and 1000 samples from MNIST for validation.</p>
<pre><code class="python">from mlxtend.data import mnist_data
from mlxtend.preprocessing import shuffle_arrays_unison
from mlxtend.tf_classifier import TfMultiLayerPerceptron
import matplotlib.pyplot as plt

X, y = mnist_data()
X, y = shuffle_arrays_unison((X, y), random_seed=1)

mlp = TfMultiLayerPerceptron(eta=0.01, 
                             epochs=30, 
                             hidden_layers=[200, 200],
                             activations=['relu', 'relu'],
                             print_progress=1, 
                             minibatches=5, 
                             optimizer='adam',
                             random_seed=1)

mlp.fit(X=X[:4000], 
        y=y[:4000],
        X_valid=X[4000:],
        y_valid=y[4000:])
</code></pre>

<pre><code>Epoch: 30/30 | Cost 0.00 | TrainAcc 1.00 | ValidAcc 0.86
</code></pre>
<pre><code class="python">plt.plot(range(1, mlp.epochs + 1), mlp.train_acc_, label='training')
plt.plot(range(1, mlp.epochs + 1), mlp.valid_acc_, label='validation')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.grid()
plt.show()
</code></pre>

<p><img alt="png" src="../TfMultiLayerPerceptron_files/TfMultiLayerPerceptron_36_0.png" /></p>
<h2 id="example-5-dropout">Example 5 -- Dropout</h2>
<p>The 3 most common techniques for preventing overfitting are <em>Early Termination</em> and <em>Regularization</em>.</p>
<p>In early termination, we stop training the network when we noticed an increasing gap between the training and validation performance. Another method is to apply regularization to reduce the number of parameters in our network and thereby reduce its complexity via this induced bias. Popular examples of regularization are L2 &amp; L1 regularization, which are essentially "penalties" against large weights that are added to the cost function. For more details, please see the documentation page at <a href="../../general_concepts/regularization-linear/"><code>general_concepts/regularization-linear</code></a>. (The multi-layer perceptron implementation supports L1 and L2 regularization via the <code>l1</code> and <code>l2</code> initialization parameters.)</p>
<p>Another regularization technique, next to L1 and L2 regularization, is dropout. In dropout, we simply "cancel" half of the "neural" connections between layers during training -- randomly. As a consequence, our neural network can never rely on any given activation to be present. Therefore, the network will attempt to learn a redundant representation just to make sure that at least some useful information remains during in epoch. As weird as it sounds, in practice, dropout makes our network more robust and helps reducing the degree of overfitting. However, keep in mind that dropout is only applied during training; during testing, evaluation, and predictions on new data, we want something that's deterministic.</p>
<pre><code class="python">from mlxtend.data import mnist_data
from mlxtend.preprocessing import shuffle_arrays_unison
from mlxtend.tf_classifier import TfMultiLayerPerceptron
import matplotlib.pyplot as plt

X, y = mnist_data()
X, y = shuffle_arrays_unison((X, y), random_seed=1)

mlp = TfMultiLayerPerceptron(eta=0.01, 
                             epochs=75, 
                             hidden_layers=[200, 200],
                             activations=['relu', 'relu'],
                             print_progress=1, 
                             minibatches=5, 
                             optimizer='adam',
                             random_seed=1,
                             dropout=0.55)

mlp.fit(X=X[:4000], 
        y=y[:4000],
        X_valid=X[4000:],
        y_valid=y[4000:])
</code></pre>

<pre><code>Epoch: 75/75 | Cost 639.21 | TrainAcc 1.00 | ValidAcc 0.90
</code></pre>
<pre><code class="python">plt.plot(range(1, mlp.epochs + 1), mlp.train_acc_, label='training')
plt.plot(range(1, mlp.epochs + 1), mlp.valid_acc_, label='validation')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.grid()
plt.show()
</code></pre>

<p><img alt="png" src="../TfMultiLayerPerceptron_files/TfMultiLayerPerceptron_40_0.png" /></p>
<h1 id="api">API</h1>
<p><em>TfMultiLayerPerceptron(eta=0.5, epochs=50, hidden_layers=[50, 10], activations=['logistic', 'logistic'], optimizer='gradientdescent', momentum=0.0, l1=0.0, l2=0.0, dropout=1.0, minibatches=1, random_seed=None, print_progress=0, dtype=None)</em></p>
<p>Multi-layer perceptron classifier.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>eta</code> : float (default: 0.5)</p>
<p>Learning rate (between 0.0 and 1.0)</p>
</li>
<li>
<p><code>epochs</code> : int (default: 50)</p>
<p>Passes over the training dataset.</p>
</li>
<li>
<p><code>hidden_layers</code> : list (default: [50, 10])</p>
<p>Number of units per hidden layer. By default 50 units in the
first hidden layer, and 10 hidden units in the second hidden layer.</p>
</li>
<li>
<p><code>activations</code> : list (default: ['logistic', 'logistic'])</p>
<p>Activation functions for each layer.
Available actiavtion functions:
"logistic", "relu", "tanh", "relu6", "elu", "softplus", "softsign"</p>
</li>
<li>
<p><code>optimizer</code> : str (default: "gradientdescent")</p>
<p>Optimizer to minimize the cost function:
"gradientdescent", "momentum", "adam", "ftrl", "adagrad"</p>
</li>
<li>
<p><code>momentum</code> : float (default: 0.0)</p>
<p>Momentum constant for momentum learning; only applies if
optimizer='momentum'</p>
</li>
<li>
<p><code>l1</code> : float (default: 0.0)</p>
<p>L1 regularization strength; only applies if optimizer='ftrl'</p>
</li>
<li>
<p><code>l2</code> : float (default: 0.0)</p>
<p>regularization strength; only applies if optimizer='ftrl'</p>
</li>
<li>
<p><code>dropout</code> : float (default: 1.0)</p>
<p>A float between in the range (0.0, 1.0] to specify
the probability that each element is kept.</p>
</li>
<li>
<p><code>minibatches</code> : int (default: 1)</p>
<p>Divide the training data into <em>k</em> minibatches
for accelerated stochastic gradient descent learning.
Gradient Descent Learning if <code>minibatches</code> = 1
Stochastic Gradient Descent learning if <code>minibatches</code> = len(y)
Minibatch learning if <code>minibatches</code> &gt; 1</p>
</li>
<li>
<p><code>random_seed</code> : int (default: None)</p>
<p>Set random state for shuffling and initializing the weights.</p>
</li>
<li>
<p><code>print_progress</code> : int (default: 0)</p>
<p>Prints progress in fitting to stderr.
0: No output
1: Epochs elapsed and cost
2: 1 plus time elapsed
3: 2 plus estimated time until completion</p>
</li>
<li>
<p><code>dtype</code> : Array-type (default: None)</p>
<p>Uses tensorflow.float32 if None.</p>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li>
<p><code>weights_</code> : 2d-array, shape=[n_features, n_classes]</p>
<p>Weights after fitting.</p>
</li>
<li>
<p><code>biases_</code> : 1D-array, shape=[n_classes]</p>
<p>Bias units after fitting.</p>
</li>
<li>
<p><code>cost_</code> : list</p>
<p>List of floats, the average cross_entropy for each epoch.</p>
</li>
</ul>
<h3 id="methods">Methods</h3>
<hr>

<p><em>fit(X, y, init_weights=True, override_minibatches=None, n_classes=None, X_valid=None, y_valid=None)</em></p>
<p>Learn weight coefficients from training data.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>init_weights</code> : bool (default: True)</p>
<p>(Re)initializes weights to small random floats if True.</p>
</li>
<li>
<p><code>override_minibatches</code> : int or None (default: None)</p>
<p>Uses a different number of minibatches for this session.</p>
</li>
<li>
<p><code>n_classes</code> : int (default: None)</p>
<p>A positive integer to declare the number of class labels
if not all class labels are present in a partial training set.
Gets the number of class labels automatically if None.
Ignored if init_weights=False.</p>
</li>
<li>
<p><code>X_valid</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Optional validation set to store the validation accuracy values
for each epoch via self.valid_acc_</p>
</li>
<li>
<p><code>y_valid</code> : array-like, shape = [n_samples]</p>
<p>Target values for X_valid</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>self</code> : object</li>
</ul>
<hr>

<p><em>predict(X)</em></p>
<p>Predict class labels of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>class_labels</code> : array-like, shape = [n_samples]</p>
<p>Predicted class labels.</p>
</li>
</ul>
<hr>

<p><em>predict_proba(X)</em></p>
<p>Predict class probabilities of X from the net input.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>Class probabilties</code> : array-like, shape= [n_samples, n_classes]</li>
</ul>
<hr>

<p><em>score(X, y)</em></p>
<p>Compute the prediction accuracy</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values (true class labels).</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>acc</code> : float</p>
<p>The prediction accuracy as a float
between 0.0 and 1.0 (perfect score).</p>
</li>
</ul></div>
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Copyright &copy; 2014-2016 <a href="http://sebastianraschka.com">Sebastian Raschka</a><br></small>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="../../../js/jquery-1.10.2.min.js"></script>
    <script src="../../../js/bootstrap-3.0.3.min.js"></script>
    <script src="../../../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '../../..';
    </script>
    <script data-main="../../../mkdocs/js/search.js" src="../../../mkdocs/js/require.js"></script>
    <script src="../../../js/base.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script src="../../../mathjaxhelper.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>
