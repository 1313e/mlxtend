<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
    <meta name="author" content="Sebastian Raschka"> 
    <link rel="canonical" href="http://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression/"> 
    <link rel="shortcut icon" href="../../../../../../favicon.ico">

    <title>SoftmaxRegression - mlxtend</title>

    <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../../css/base.css" rel="stylesheet">
    <link href="../../../css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../css/highlight.css">


    <link href="../../../extra.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-38457794-2', 'rasbt.github.io/mlxtend/');
    ga('send', 'pageview');
    </script>
    
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->
            <a class="navbar-brand" href="../../..">mlxtend</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../USER_GUIDE_INDEX/">USER GUIDE INDEX</a>
</li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">classifier</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../EnsembleVoteClassifier/">EnsembleVoteClassifier</a>
</li>

        
            
<li >
    <a href="../Perceptron/">Perceptron</a>
</li>

        
            
<li >
    <a href="../Adaline/">Adaline</a>
</li>

        
            
<li >
    <a href="../LogisticRegression/">LogisticRegression</a>
</li>

        
            
<li >
    <a href="../NeuralNetMLP/">NeuralNetMLP</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regressor</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regressor/LinearRegression/">LinearRegression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regression_utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regression_utils/plot_linear_regression/">Plot linear regression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_selection</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_selection/SequentialFeatureSelector/">SequentialFeatureSelector</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">evaluate</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../evaluate/confusion_matrix/">Confusion matrix</a>
</li>

        
            
<li >
    <a href="../../evaluate/plot_decision_regions/">Plot decision regions</a>
</li>

        
            
<li >
    <a href="../../evaluate/plot_learning_curves/">Plot learning curves</a>
</li>

        
            
<li >
    <a href="../../evaluate/scoring/">Scoring</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">preprocessing</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../preprocessing/DenseTransformer/">DenseTransformer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/MeanCenterer/">MeanCenterer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/minmax_scaling/">Minmax scaling</a>
</li>

        
            
<li >
    <a href="../../preprocessing/shuffle_arrays_unison/">Shuffle arrays unison</a>
</li>

        
            
<li >
    <a href="../../preprocessing/standardize/">Standardize</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">data</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../data/autompg_data/">Autompg data</a>
</li>

        
            
<li >
    <a href="../../data/boston_housing_data/">Boston housing data</a>
</li>

        
            
<li >
    <a href="../../data/iris_data/">Iris data</a>
</li>

        
            
<li >
    <a href="../../data/mnist_data/">Mnist data</a>
</li>

        
            
<li >
    <a href="../../data/load_mnist/">Load mnist</a>
</li>

        
            
<li >
    <a href="../../data/wine_data/">Wine data</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">file_io</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../file_io/find_filegroups/">Find filegroups</a>
</li>

        
            
<li >
    <a href="../../file_io/find_files/">Find files</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general plotting</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../general_plotting/category_scatter/">Category scatter</a>
</li>

        
            
<li >
    <a href="../../general_plotting/enrichment_plot/">Enrichment plot</a>
</li>

        
            
<li >
    <a href="../../general_plotting/stacked_barplot/">Stacked barplot</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">math</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../math/num_combinations/">Num combinations</a>
</li>

        
            
<li >
    <a href="../../math/num_permutations/">Num permutations</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">text</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../text/generalize_names/">Generalize names</a>
</li>

        
            
<li >
    <a href="../../text/generalize_names_duplcheck/">Generalize names duplcheck</a>
</li>

        
            
<li >
    <a href="../../text/tokenizer/">Tokenizer</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../utils/Counter/">Counter</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general concepts</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../general_concepts/activation-functions/">Activation functions</a>
</li>

        
            
<li >
    <a href="../../general_concepts/gradient-optimization/">Gradient optimization</a>
</li>

        
            
<li >
    <a href="../../general_concepts/linear-gradient-derivative/">Linear gradient derivative</a>
</li>

        
            
<li >
    <a href="../../general_concepts/regularization-linear/">Regularization linear</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">Upcoming Features / 0.3.1dev</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../tf_classifier/TfSoftmaxRegression/">TfSoftmaxRegression</a>
</li>

        
            
<li class="active">
    <a href="./">SoftmaxRegression</a>
</li>

        
            
<li >
    <a href="../../regressor/StackingRegressor/">StackingRegressor</a>
</li>

        
            
<li >
    <a href="../StackingClassifier/">StackingClassifier</a>
</li>

        
            
<li >
    <a href="../../preprocessing/one-hot_encoding/">One hot encoding</a>
</li>

        
    </ul>
  </li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.classifier/">Mlxtend.classifier</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.data/">Mlxtend.data</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.evaluate/">Mlxtend.evaluate</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.feature_selection/">Mlxtend.feature selection</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.file_io/">Mlxtend.file io</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.general_plotting/">Mlxtend.general plotting</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.preprocessing/">Mlxtend.preprocessing</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regression_utils/">Mlxtend.regression utils</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regressor/">Mlxtend.regressor</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.text/">Mlxtend.text</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.utils/">Mlxtend.utils</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../../../installation/">Installation</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../changelog/">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../../../contributing/">Contributing</a>
</li>

                        
                            
<li >
    <a href="../../../license/">License</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>
            

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                
                    <li >
                        <a rel="next" href="../../tf_classifier/TfSoftmaxRegression/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../../regressor/StackingRegressor/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                
                
                    <li>
                        <a href="https://github.com/rasbt/mlxtend">
                            
                                <i class="fa fa-github"></i>
                            
                            GitHub
                        </a>
                    </li>
                
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#softmax-regression">Softmax Regression</a></li>
        
    
        <li class="main "><a href="#overview">Overview</a></li>
        
    
        <li class="main "><a href="#examples">Examples</a></li>
        
            <li><a href="#example-1-gradient-descent">Example 1 - Gradient Descent</a></li>
        
            <li><a href="#example-2-stochastic-gradient-descent">Example 2 - Stochastic Gradient Descent</a></li>
        
    
        <li class="main "><a href="#api">API</a></li>
        
            <li><a href="#methods">Methods</a></li>
        
            <li><a href="#properties">Properties</a></li>
        
    
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="softmax-regression">Softmax Regression</h1>
<p>A logistic regression class for multi-class classification tasks.</p>
<blockquote>
<p>from mlxtend.classifier import SoftmaxRegression</p>
</blockquote>
<h1 id="overview">Overview</h1>
<p><em>Softmax Regression</em> (synonyms: <em>Multinomial Logistic</em>, <em>Maximum Entropy Classifier</em>, or just <em>Multi-class Logistic Regression</em>) is a generalization of logistic regression that we can use for multi-class classification (under the assumption that the classes are  mutually exclusive). In contrast, we use the (standard) <em>Logistic Regression</em> model in binary classification tasks.</p>
<p>Below is a schematic of a <em>Logistic Regression</em> model, for more details, please see the <a href="../LogisticRegression/"><code>LogisticRegression</code> manual</a>.</p>
<p><img alt="" src="../SoftmaxRegression_files/logistic_regression_schematic.png" /></p>
<p>In <em>Softmax Regression</em> (SMR), we replace the sigmoid logistic function by the so-called <em>softmax</em> function <mathjax>$\phi_{softmax}(\cdot)$</mathjax>.</p>
<p><mathjax>$$P(y=j \mid z^{(i)}) = \phi_{softmax}(z^{(i)}) = \frac{e^{z^{(i)}}}{\sum_{j=0}^{k} e^{z_{k}^{(i)}}},$$</mathjax></p>
<p>where we define the net input <em>z</em> as </p>
<p><mathjax>$$z = w_1x_1 + ... + w_mx_m  + b= \sum_{l=0}^{m} w_l x_l + b= \mathbf{w}^T\mathbf{x} + b.$$</mathjax> </p>
<p>(<strong>w</strong> is the weight vector, <mathjax>$\mathbf{x}$</mathjax> is the feature vector of 1 training sample, and <mathjax>$b$</mathjax> is the bias unit.) <br />
Now, this softmax function computes the probability that this training sample <mathjax>$\mathbf{x}^{(i)}$</mathjax> belongs to class <mathjax>$j$</mathjax> given the weight and net input <mathjax>$z^{(i)}$</mathjax>. So, we compute the probability <mathjax>$p(y = j \mid \mathbf{x^{(i)}; w}_j)$</mathjax> for each class label in  <mathjax>$j = 1, \ldots, k.$</mathjax>. Note the normalization term in the denominator which causes these class probabilities to sum up to one.</p>
<p><img alt="" src="../SoftmaxRegression_files/softmax_schematic_1.png" /></p>
<p>To illustrate the concept of softmax, let us walk through a concrete example. Let's assume we have a training set consisting of 4 samples from 3 different classes (0, 1, and 2)</p>
<ul>
<li><mathjax>$x_0 \rightarrow \text{class }0$</mathjax></li>
<li><mathjax>$x_1 \rightarrow \text{class }1$</mathjax></li>
<li><mathjax>$x_2 \rightarrow \text{class }2$</mathjax></li>
<li><mathjax>$x_3 \rightarrow \text{class }2$</mathjax></li>
</ul>
<pre><code class="python">import numpy as np
y = np.array([0, 1, 2, 2])
</code></pre>

<p>First, we want to encode the class labels into a format that we can more easily work with; we apply one-hot encoding:</p>
<pre><code class="python">y_enc = (np.arange(np.max(y) + 1) == y[:, None]).astype(float)
print('one-hot encoding:\n', y_enc)
</code></pre>

<pre><code>one-hot encoding:
 [[ 1.  0.  0.]
 [ 0.  1.  0.]
 [ 0.  0.  1.]
 [ 0.  0.  1.]]
</code></pre>
<p>A sample that belongs to class 0 (the first row) has a 1 in the first cell, a sample that belongs to class 2 has a 1 in the second cell of its row, and so forth.</p>
<p>Next, let us define the feature matrix of our 4 training samples. Here, we assume that our dataset consists of 2 features; thus, we create a 4x2 dimensional matrix of our samples and features.
Similarly, we create a 2x3 dimensional weight matrix (one row per feature and one column for each class).</p>
<pre><code class="python">X = np.array([[0.1, 0.5],
              [1.1, 2.3],
              [-1.1, -2.3],
              [-1.5, -2.5]])

W = np.array([[0.1, 0.2, 0.3],
              [0.1, 0.2, 0.3]])

bias = np.array([0.01, 0.1, 0.1])

print('Inputs X:\n', X)
print('\nWeights W:\n', W)
print('\nbias:\n', bias)
</code></pre>

<pre><code>Inputs X:
 [[ 0.1  0.5]
 [ 1.1  2.3]
 [-1.1 -2.3]
 [-1.5 -2.5]]

Weights W:
 [[ 0.1  0.2  0.3]
 [ 0.1  0.2  0.3]]

bias:
 [ 0.01  0.1   0.1 ]
</code></pre>
<p>To compute the net input, we multiply the 4x2 matrix feature matrix <code>X</code> with the 2x3 (n_features x n_classes) weight matrix <code>W</code>, which yields a 4x3 output matrix (n_samples x n_classes) to which we then add the bias unit: </p>
<p><mathjax>$$\mathbf{Z} = \mathbf{X}\mathbf{W} + \mathbf{b}.$$</mathjax></p>
<pre><code class="python">X = np.array([[0.1, 0.5],
              [1.1, 2.3],
              [-1.1, -2.3],
              [-1.5, -2.5]])

W = np.array([[0.1, 0.2, 0.3],
              [0.1, 0.2, 0.3]])

bias = np.array([0.01, 0.1, 0.1])

print('Inputs X:\n', X)
print('\nWeights W:\n', W)
print('\nbias:\n', bias)
</code></pre>

<pre><code>Inputs X:
 [[ 0.1  0.5]
 [ 1.1  2.3]
 [-1.1 -2.3]
 [-1.5 -2.5]]

Weights W:
 [[ 0.1  0.2  0.3]
 [ 0.1  0.2  0.3]]

bias:
 [ 0.01  0.1   0.1 ]
</code></pre>
<pre><code class="python">def net_input(X, W, b):
    return (X.dot(W) + b)

net_in = net_input(X, W, bias)
print('net input:\n', net_in)
</code></pre>

<pre><code>net input:
 [[ 0.07  0.22  0.28]
 [ 0.35  0.78  1.12]
 [-0.33 -0.58 -0.92]
 [-0.39 -0.7  -1.1 ]]
</code></pre>
<p>Now, it's time to compute the softmax activation that we discussed earlier:</p>
<p><mathjax>$$P(y=j \mid z^{(i)}) = \phi_{softmax}(z^{(i)}) = \frac{e^{z^{(i)}}}{\sum_{j=0}^{k} e^{z_{k}^{(i)}}}.$$</mathjax></p>
<pre><code class="python">def softmax(z):
    return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T

smax = softmax(net_in)
print('softmax:\n', smax)
</code></pre>

<pre><code>softmax:
 [[ 0.29450637  0.34216758  0.36332605]
 [ 0.21290077  0.32728332  0.45981591]
 [ 0.42860913  0.33380113  0.23758974]
 [ 0.44941979  0.32962558  0.22095463]]
</code></pre>
<p>As we can see, the values for each sample (row) nicely sum up to 1 now. E.g., we can say that the first sample <br />
<code>[ 0.29450637  0.34216758  0.36332605]</code> has a 29.45% probability to belong to class 0.</p>
<p>Now, in order to turn these probabilities back into class labels, we could simply take the argmax-index position of each row:</p>
<p>[[ 0.29450637  0.34216758  <strong>0.36332605</strong>] -&gt; 2 <br />
[ 0.21290077  0.32728332  <strong>0.45981591</strong>]  -&gt; 2<br />
[ <strong>0.42860913</strong>  0.33380113  0.23758974]  -&gt; 0<br />
[ <strong>0.44941979</strong>  0.32962558  0.22095463]] -&gt; 0  </p>
<pre><code class="python">def to_classlabel(z):
    return z.argmax(axis=1)

print('predicted class labels: ', to_classlabel(smax))
</code></pre>

<pre><code>predicted class labels:  [2 2 0 0]
</code></pre>
<p>As we can see, our predictions are terribly wrong, since the correct class labels are <code>[0, 1, 2, 2]</code>. Now, in order to train our logistic model (e.g., via an optimization algorithm such as gradient descent), we need to define a cost function <mathjax>$J(\cdot)$</mathjax> that we want to minimize:</p>
<p><mathjax>$$J(\theta) = \frac{1}{n} \sum_{i=1}^{n} H(T_i, O_i),$$</mathjax></p>
<p>which is the average of all cross-entropies over our <mathjax>$n$</mathjax> training samples. The cross-entropy  function is defined as</p>
<p><mathjax>$$H(T_i, O_i) = -\sum_m T_i \cdot log(O_i).$$</mathjax></p>
<p>Here the <mathjax>$T$</mathjax> stands for "target" (i.e., the <em>true</em> class labels) and the <mathjax>$O$</mathjax> stands for output -- the computed <em>probability</em> via softmax; <strong>not</strong> the predicted class label.</p>
<pre><code class="python">def cross_entropy(output, y_target):
    return - np.sum(np.log(output) * (y_target), axis=1)

xent = cross_entropy(smax, y_enc)
print('Cross Entropy:', xent)
</code></pre>

<pre><code>Cross Entropy: [ 1.22245465  1.11692907  1.43720989  1.50979788]
</code></pre>
<pre><code class="python">def cost(output, y_target):
    return np.mean(cross_entropy(output, y_target))

J_cost = cost(smax, y_enc)
print('Cost: ', J_cost)
</code></pre>

<pre><code>Cost:  1.32159787159
</code></pre>
<p>In order to learn our softmax model -- determining the weight coefficients -- via gradient descent, we then need to compute the derivative </p>
<p><mathjax>$$\nabla \mathbf{w}_j \, J(\mathbf{W}).$$</mathjax></p>
<p>I don't want to walk through the tedious details here, but this cost derivative turns out to be simply:</p>
<p><mathjax>$$\nabla \mathbf{w}_j \, J(\mathbf{W}) = - \frac{1}{n} \sum^{n}_{i=0} \big[\mathbf{x}^{(i)}\ \big(T_i - O_i \big) \big]$$</mathjax></p>
<p>We can then use the cost derivate to update the weights in opposite direction of the cost gradient with learning rate <mathjax>$\eta$</mathjax>:</p>
<p><mathjax>$$\mathbf{w}_j := \mathbf{w}_j - \eta \nabla \mathbf{w}_j \, J(\mathbf{W})$$</mathjax> </p>
<p>for each class <mathjax>$$j \in \{0, 1, ..., k\}.$$</mathjax></p>
<p>(Note that <mathjax>$\mathbf{w}_j$</mathjax> is the weight vector for the class <mathjax>$y=j$</mathjax>.)</p>
<p>As a penalty against complexity, an approach to reduce the variance of our model and decrease the degree of overfitting by adding additional bias, we can further add a regularization term such as the L2 term with the regularization parameter <mathjax>$\lambda$</mathjax>:</p>
<p>L2:        <mathjax>$\frac{\lambda}{2} ||w||_2$</mathjax>, </p>
<p>so that our cost function becomes</p>
<p><mathjax>$$J(\theta) = \frac{1}{n} \sum_{i=1}^{n} H(T_i, O_i) + \frac{\lambda}{2} ||w||_2$$</mathjax></p>
<p>and we define the "regularized" weight update as</p>
<p><mathjax>$$\mathbf{w}_j := \mathbf{w}_j -  \eta \big[\nabla \mathbf{w}_j \, J(\mathbf{W}) + \lambda w_j\big].$$</mathjax> </p>
<h1 id="examples">Examples</h1>
<h2 id="example-1-gradient-descent">Example 1 - Gradient Descent</h2>
<pre><code class="python">from mlxtend.data import iris_data
from mlxtend.evaluate import plot_decision_regions
from mlxtend.classifier import SoftmaxRegression
import matplotlib.pyplot as plt

# Loading Data

X, y = iris_data()
X = X[:, [0, 3]] # sepal length and petal width

# standardize
X[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()
X[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()

lr = SoftmaxRegression(eta=0.005, epochs=200, minibatches=1, random_seed=1)
lr.fit(X, y)

plot_decision_regions(X, y, clf=lr)
plt.title('Softmax Regression - Stochastic Gradient Descent')
plt.show()

plt.plot(range(len(lr.cost_)), lr.cost_)
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.show()
</code></pre>

<p><img alt="png" src="../SoftmaxRegression_files/SoftmaxRegression_34_0.png" /></p>
<p><img alt="png" src="../SoftmaxRegression_files/SoftmaxRegression_34_1.png" /></p>
<h3 id="predicting-class-labels">Predicting Class Labels</h3>
<pre><code class="python">y_pred = lr.predict(X)
print('Last 3 Class Labels: %s' % y_pred[-3:])
</code></pre>

<pre><code>Last 3 Class Labels: [2 2 2]
</code></pre>
<h3 id="predicting-class-probabilities">Predicting Class Probabilities</h3>
<pre><code class="python">y_pred = lr.predict_proba(X)
print('Last 3 Class Labels:\n %s' % y_pred[-3:])
</code></pre>

<pre><code>Last 3 Class Labels:
 [[  4.99921674e-06   7.23245885e-02   9.27670412e-01]
 [  2.50487208e-07   1.20047952e-02   9.87994954e-01]
 [  2.14388120e-04   2.95955727e-01   7.03829884e-01]]
</code></pre>
<h2 id="example-2-stochastic-gradient-descent">Example 2 - Stochastic Gradient Descent</h2>
<pre><code class="python">from mlxtend.data import iris_data
from mlxtend.evaluate import plot_decision_regions
from mlxtend.classifier import SoftmaxRegression
import matplotlib.pyplot as plt

# Loading Data

X, y = iris_data()
X = X[:, [0, 3]] # sepal length and petal width

# standardize
X[:,0] = (X[:,0] - X[:,0].mean()) / X[:,0].std()
X[:,1] = (X[:,1] - X[:,1].mean()) / X[:,1].std()

lr = SoftmaxRegression(eta=0.005, epochs=200, minibatches=len(y), random_seed=1)
lr.fit(X, y)

plot_decision_regions(X, y, clf=lr)
plt.title('Softmax Regression - Stochastic Gradient Descent')
plt.show()

plt.plot(range(len(lr.cost_)), lr.cost_)
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.show()
</code></pre>

<p><img alt="png" src="../SoftmaxRegression_files/SoftmaxRegression_40_0.png" /></p>
<p><img alt="png" src="../SoftmaxRegression_files/SoftmaxRegression_40_1.png" /></p>
<h1 id="api">API</h1>
<p><em>SoftmaxRegression(eta=0.01, epochs=50, l2_lambda=0.0, minibatches=1, random_seed=None, zero_init_weight=False, print_progress=0)</em></p>
<p>Logistic regression classifier.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>eta</code> : float (default: 0.01)</p>
<p>Learning rate (between 0.0 and 1.0)</p>
</li>
<li>
<p><code>epochs</code> : int (default: 50)</p>
<p>Passes over the training dataset.</p>
</li>
<li>
<p><code>l2_lambda</code> : float</p>
<p>Regularization parameter for L2 regularization.
No regularization if l2_lambda=0.0.</p>
</li>
<li>
<p><code>minibatches</code> : int (default: 1)</p>
<p>Divide the training data into <em>k</em> minibatches
for accelerated stochastic gradient descent learning.
Gradient Descent Learning if <code>minibatches</code> = 1
Stochastic Gradient Descent learning if <code>minibatches</code> = len(y)
Minibatch learning if <code>minibatches</code> &gt; 1</p>
</li>
<li>
<p><code>random_seed</code> : int (default: None)</p>
<p>Set random state for shuffling and initializing the weights.</p>
</li>
<li>
<p><code>zero_init_weight</code> : bool (default: False)</p>
<p>If True, weights are initialized to zero instead of small random
numbers following a standard normal distribution with mean=0 and
stddev=1.</p>
</li>
<li>
<p><code>print_progress</code> : int (default: 0)</p>
<p>Prints progress in fitting to stderr.
0: No output
1: Epochs elapsed and cost
2: 1 plus time elapsed
3: 2 plus estimated time until completion</p>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li>
<p><code>w_</code> : 1d-array</p>
<p>Weights after fitting.</p>
</li>
<li>
<p><code>cost_</code> : list</p>
<p>List of floats with sum of squared error cost (sgd or gd) for every
epoch.</p>
</li>
</ul>
<h3 id="methods">Methods</h3>
<hr>

<p><em>fit(X, y, init_weights=True)</em></p>
<p>Learn weight coefficients from training data.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
<li>
<p><code>init_weights</code> : bool (default: True)</p>
<p>(Re)initializes weights to small random floats if True.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>self</code> : object</li>
</ul>
<hr>

<p><em>predict(X)</em></p>
<p>Predict class labels of X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>class_labels</code> : array-like, shape = [n_samples]</p>
<p>Predicted class labels.</p>
</li>
</ul>
<hr>

<p><em>predict_proba(X)</em></p>
<p>Predict class probabilities of X from the net input.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>Class probabilties</code> : array-like, shape= [n_samples, n_classes]</li>
</ul>
<h3 id="properties">Properties</h3></div>
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Copyright &copy; 2014-2016 <a href="http://sebastianraschka.com">Sebastian Raschka</a><br></small>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="../../../js/jquery-1.10.2.min.js"></script>
    <script src="../../../js/bootstrap-3.0.3.min.js"></script>
    <script src="../../../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '../../..';
    </script>
    <script data-main="../../../mkdocs/js/search.js" src="../../../mkdocs/js/require.js"></script>
    <script src="../../../js/base.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script src="../../../mathjaxhelper.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>
