<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
    <meta name="author" content="Sebastian Raschka"> 
    <link rel="canonical" href="http://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/"> 
    <link rel="shortcut icon" href="../../../../../../favicon.ico">

    <title>EnsembleVoteClassifier - mlxtend</title>

    <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../../css/base.css" rel="stylesheet">
    <link href="../../../css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../css/highlight.css">


    <link href="../../../extra.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-38457794-2', 'rasbt.github.io/mlxtend/');
    ga('send', 'pageview');
    </script>
    
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->
            <a class="navbar-brand" href="../../..">mlxtend</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../USER_GUIDE_INDEX/">USER GUIDE INDEX</a>
</li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">classifier</a>
    <ul class="dropdown-menu">
        
            
<li class="active">
    <a href="./">EnsembleVoteClassifier</a>
</li>

        
            
<li >
    <a href="../Perceptron/">Perceptron</a>
</li>

        
            
<li >
    <a href="../Adaline/">Adaline</a>
</li>

        
            
<li >
    <a href="../LogisticRegression/">LogisticRegression</a>
</li>

        
            
<li >
    <a href="../NeuralNetMLP/">NeuralNetMLP</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regressor</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regressor/LinearRegression/">LinearRegression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regression_utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regression_utils/plot_linear_regression/">Plot linear regression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_selection</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_selection/SequentialFeatureSelector/">SequentialFeatureSelector</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_extraction</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_extraction/PrincipalComponentAnalysis/">PrincipalComponentAnalysis</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">evaluate</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../evaluate/confusion_matrix/">Confusion matrix</a>
</li>

        
            
<li >
    <a href="../../evaluate/plot_decision_regions/">Plot decision regions</a>
</li>

        
            
<li >
    <a href="../../evaluate/plot_learning_curves/">Plot learning curves</a>
</li>

        
            
<li >
    <a href="../../evaluate/scoring/">Scoring</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">preprocessing</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../preprocessing/DenseTransformer/">DenseTransformer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/MeanCenterer/">MeanCenterer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/minmax_scaling/">Minmax scaling</a>
</li>

        
            
<li >
    <a href="../../preprocessing/shuffle_arrays_unison/">Shuffle arrays unison</a>
</li>

        
            
<li >
    <a href="../../preprocessing/standardize/">Standardize</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">data</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../data/autompg_data/">Autompg data</a>
</li>

        
            
<li >
    <a href="../../data/boston_housing_data/">Boston housing data</a>
</li>

        
            
<li >
    <a href="../../data/iris_data/">Iris data</a>
</li>

        
            
<li >
    <a href="../../data/mnist_data/">Mnist data</a>
</li>

        
            
<li >
    <a href="../../data/load_mnist/">Load mnist</a>
</li>

        
            
<li >
    <a href="../../data/wine_data/">Wine data</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">file_io</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../file_io/find_filegroups/">Find filegroups</a>
</li>

        
            
<li >
    <a href="../../file_io/find_files/">Find files</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general plotting</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../general_plotting/category_scatter/">Category scatter</a>
</li>

        
            
<li >
    <a href="../../general_plotting/enrichment_plot/">Enrichment plot</a>
</li>

        
            
<li >
    <a href="../../general_plotting/stacked_barplot/">Stacked barplot</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">math</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../math/num_combinations/">Num combinations</a>
</li>

        
            
<li >
    <a href="../../math/num_permutations/">Num permutations</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">text</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../text/generalize_names/">Generalize names</a>
</li>

        
            
<li >
    <a href="../../text/generalize_names_duplcheck/">Generalize names duplcheck</a>
</li>

        
            
<li >
    <a href="../../text/tokenizer/">Tokenizer</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../utils/Counter/">Counter</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general concepts</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../general_concepts/activation-functions/">Activation functions</a>
</li>

        
            
<li >
    <a href="../../general_concepts/gradient-optimization/">Gradient optimization</a>
</li>

        
            
<li >
    <a href="../../general_concepts/linear-gradient-derivative/">Linear gradient derivative</a>
</li>

        
            
<li >
    <a href="../../general_concepts/regularization-linear/">Regularization linear</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">Upcoming Features / 0.3.1dev</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_extraction/PrincipalComponentAnalysis/">PrincipalComponentAnalysis</a>
</li>

        
            
<li >
    <a href="../../tf_classifier/TfMultiLayerPerceptron/">TfMultiLayerPerceptron</a>
</li>

        
            
<li >
    <a href="../../tf_classifier/TfSoftmaxRegression/">TfSoftmaxRegression</a>
</li>

        
            
<li >
    <a href="../SoftmaxRegression/">SoftmaxRegression</a>
</li>

        
            
<li >
    <a href="../../regressor/StackingRegressor/">StackingRegressor</a>
</li>

        
            
<li >
    <a href="../StackingClassifier/">StackingClassifier</a>
</li>

        
            
<li >
    <a href="../../preprocessing/one-hot_encoding/">One hot encoding</a>
</li>

        
    </ul>
  </li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.classifier/">Mlxtend.classifier</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.data/">Mlxtend.data</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.evaluate/">Mlxtend.evaluate</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.feature_selection/">Mlxtend.feature selection</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.file_io/">Mlxtend.file io</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.general_plotting/">Mlxtend.general plotting</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.preprocessing/">Mlxtend.preprocessing</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regression_utils/">Mlxtend.regression utils</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regressor/">Mlxtend.regressor</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.text/">Mlxtend.text</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.utils/">Mlxtend.utils</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../../../installation/">Installation</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../changelog/">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../../../contributing/">Contributing</a>
</li>

                        
                            
<li >
    <a href="../../../license/">License</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>
            

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                
                    <li >
                        <a rel="next" href="../../../USER_GUIDE_INDEX/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../Perceptron/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                
                
                    <li>
                        <a href="https://github.com/rasbt/mlxtend">
                            
                                <i class="fa fa-github"></i>
                            
                            GitHub
                        </a>
                    </li>
                
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#ensemblevoteclassifier">EnsembleVoteClassifier</a></li>
        
    
        <li class="main "><a href="#overview">Overview</a></li>
        
            <li><a href="#majority-voting-hard-voting">Majority Voting / Hard Voting</a></li>
        
            <li><a href="#weighted-majority-vote">Weighted Majority Vote</a></li>
        
            <li><a href="#soft-voting">Soft Voting</a></li>
        
            <li><a href="#references">References</a></li>
        
    
        <li class="main "><a href="#examples">Examples</a></li>
        
            <li><a href="#example-1-classifying-iris-flowers-using-different-classification-models">Example 1 -  Classifying Iris Flowers Using Different Classification Models</a></li>
        
            <li><a href="#example-2-grid-search">Example 2 - Grid Search</a></li>
        
    
        <li class="main "><a href="#api">API</a></li>
        
            <li><a href="#methods">Methods</a></li>
        
    
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="ensemblevoteclassifier">EnsembleVoteClassifier</h1>
<p>Implementation of a majority voting <code>EnsembleVoteClassifier</code> for classification.</p>
<blockquote>
<p>from mlxtend.classifier import EnsembleVoteClassifier</p>
</blockquote>
<h1 id="overview">Overview</h1>
<p>The <code>EnsembleVoteClassifier</code> is a meta-classifier for combining similar or conceptually different machine learning classifiers for classification via majority or plurality voting. (For simplicity, we will refer to both majority and plurality voting as majority voting.)</p>
<p><img alt="" src="../EnsembleVoteClassifier_files/voting.png" /></p>
<p>The <code>EnsembleVoteClassifier</code> implements "hard" and "soft" voting. In hard voting, we predict the final class label as the class label that has been predicted most frequently by the classification models. In soft voting, we predict the class labels by averaging the class-probabilities (only recommended if the classifiers are well-calibrated).</p>
<p><img alt="" src="../EnsembleVoteClassifier_files/majority_voting.png" /></p>
<p><strong>Note</strong></p>
<p>If you are interested in using the <code>EnsembleVoteClassifier</code>, please note that it is now also available through scikit learn (&gt;0.17) as <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html"><code>VotingClassifier</code></a>.</p>
<h3 id="majority-voting-hard-voting">Majority Voting / Hard Voting</h3>
<p>Hard voting is the simplest case of majority voting. Here, we predict the class label <mathjax>$\hat{y}$</mathjax> via majority (plurality) voting of each classifier <mathjax>$C_j$</mathjax>:</p>
<p><mathjax>$$\hat{y}=mode\{C_1(\mathbf{x}), C_2(\mathbf{x}), ..., C_m(\mathbf{x})\}$$</mathjax></p>
<p>Assuming that we combine three classifiers that classify a training sample as follows:</p>
<ul>
<li>classifier 1 -&gt; class 0</li>
<li>classifier 2 -&gt; class 0</li>
<li>classifier 3 -&gt; class 1</li>
</ul>
<p><mathjax>$$\hat{y}=mode\{0, 0, 1\} = 0$$</mathjax></p>
<p>Via majority vote, we would we would classify the sample as "class 0."</p>
<h3 id="weighted-majority-vote">Weighted Majority Vote</h3>
<p>In addition to the simple majority vote (hard voting) as described in the previous section, we can compute a weighted majority vote by associating a weight <mathjax>$w_j$</mathjax> with classifier <mathjax>$C_j$</mathjax>:</p>
<p><mathjax>$$\hat{y} = \arg \max_i \sum^{m}_{j=1} w_j \chi_A \big(C_j(\mathbf{x})=i\big),$$</mathjax></p>
<p>where <mathjax>$\chi_A$</mathjax> is the characteristic function <mathjax>$[C_j(\mathbf{x}) = i \; \in A]$</mathjax>, and <mathjax>$A$</mathjax> is the set of unique class labels. </p>
<p>Continuing with the example from the previous section</p>
<ul>
<li>classifier 1 -&gt; class 0</li>
<li>classifier 2 -&gt; class 0</li>
<li>classifier 3 -&gt; class 1</li>
</ul>
<p>assigning the weights {0.2, 0.2, 0.6} would yield a prediction <mathjax>$\hat{y} = 1$</mathjax>:</p>
<p><mathjax>$$\arg \max_i [0.2 \times i_0 + 0.2 \times i_0 + 0.6 \times i_1] = 1$$</mathjax></p>
<h3 id="soft-voting">Soft Voting</h3>
<p>In soft voting, we predict the class labels based on the predicted probabilities <mathjax>$p$</mathjax> for classifier -- this approach is only recommended if the classifiers are well-calibrated.</p>
<p><mathjax>$$\hat{y} = \arg \max_i \sum^{m}_{j=1} w_j p_{ij},$$</mathjax></p>
<p>where <mathjax>$w_j$</mathjax> is the weight that can be assigned to the <mathjax>$j$</mathjax>th classifier.</p>
<p>Assuming the example in the previous section was a binary classification task with class labels <mathjax>$i \in \{0, 1\}$</mathjax>, our ensemble could make the following prediction:</p>
<ul>
<li><mathjax>$C_1(\mathbf{x}) \rightarrow [0.9, 0.1]$</mathjax></li>
<li><mathjax>$C_2(\mathbf{x}) \rightarrow [0.8, 0.2]$</mathjax></li>
<li><mathjax>$C_3(\mathbf{x}) \rightarrow [0.4, 0.6]$</mathjax></li>
</ul>
<p>Using uniform weights, we compute the average probabilities:</p>
<p><mathjax>$$p(i_0 \mid \mathbf{x}) = \frac{0.9 + 0.8 + 0.4}{3} = 0.7 \\\\
p(i_1 \mid \mathbf{x}) = \frac{0.1 + 0.2 + 0.6}{3} = 0.3$$</mathjax></p>
<p><mathjax>$$\hat{y} = \arg \max_i \big[p(i_0 \mid \mathbf{x}), p(i_1 \mid \mathbf{x}) \big] = 0$$</mathjax></p>
<p>However, assigning the weights {0.1, 0.1, 0.8} would yield a prediction <mathjax>$\hat{y} = 1$</mathjax>:</p>
<p><mathjax>$$p(i_0 \mid \mathbf{x}) = {0.1 \times 0.9 + 0.1 \times 0.8 + 0.8 \times  0.4} = 0.49 \\\\
p(i_1 \mid \mathbf{x}) = {0.1 \times 0.1 + 0.2 \times 0.1 + 0.8 \times 0.6} = 0.51$$</mathjax></p>
<p><mathjax>$$\hat{y} = \arg \max_i \big[p(i_0 \mid \mathbf{x}), p(i_1 \mid \mathbf{x}) \big] = 1$$</mathjax></p>
<h3 id="references">References</h3>
<ul>
<li>[1] S. Raschka. <a href="https://github.com/rasbt/python-machine-learning-book">Python Machine Learning</a>. Packt Publishing Ltd., 2015.</li>
</ul>
<h1 id="examples">Examples</h1>
<h2 id="example-1-classifying-iris-flowers-using-different-classification-models">Example 1 -  Classifying Iris Flowers Using Different Classification Models</h2>
<pre><code class="python">from sklearn import datasets

iris = datasets.load_iris()
X, y = iris.data[:, 1:3], iris.target
</code></pre>

<pre><code class="python">from sklearn import cross_validation
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB 
from sklearn.ensemble import RandomForestClassifier
import numpy as np

clf1 = LogisticRegression(random_state=1)
clf2 = RandomForestClassifier(random_state=1)
clf3 = GaussianNB()

print('5-fold cross validation:\n')

for clf, label in zip([clf1, clf2, clf3], ['Logistic Regression', 'Random Forest', 'Naive Bayes']):

    scores = cross_validation.cross_val_score(clf, X, y, cv=5, scoring='accuracy')
    print(&quot;Accuracy: %0.2f (+/- %0.2f) [%s]&quot; % (scores.mean(), scores.std(), label))
</code></pre>

<pre><code>5-fold cross validation:

Accuracy: 0.90 (+/- 0.05) [Logistic Regression]
Accuracy: 0.93 (+/- 0.05) [Random Forest]
Accuracy: 0.91 (+/- 0.04) [Naive Bayes]
</code></pre>
<pre><code class="python">from mlxtend.classifier import EnsembleVoteClassifier

eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,1])

for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']):

    scores = cross_validation.cross_val_score(clf, X, y, cv=5, scoring='accuracy')
    print(&quot;Accuracy: %0.2f (+/- %0.2f) [%s]&quot; % (scores.mean(), scores.std(), label))
</code></pre>

<pre><code>Accuracy: 0.90 (+/- 0.05) [Logistic Regression]
Accuracy: 0.93 (+/- 0.05) [Random Forest]
Accuracy: 0.91 (+/- 0.04) [Naive Bayes]
Accuracy: 0.95 (+/- 0.05) [Ensemble]
</code></pre>
<h4 id="plotting-decision-regions">Plotting Decision Regions</h4>
<pre><code class="python">import matplotlib.pyplot as plt
from mlxtend.evaluate import plot_decision_regions
import matplotlib.gridspec as gridspec
import itertools

gs = gridspec.GridSpec(2, 2)

fig = plt.figure(figsize=(10,8))

for clf, lab, grd in zip([clf1, clf2, clf3, eclf],
                         ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble'],
                         itertools.product([0, 1], repeat=2)):

    clf.fit(X, y)
    ax = plt.subplot(gs[grd[0], grd[1]])
    fig = plot_decision_regions(X=X, y=y, clf=clf)
    plt.title(lab)
</code></pre>

<p><img alt="png" src="../EnsembleVoteClassifier_files/EnsembleVoteClassifier_27_0.png" /></p>
<h2 id="example-2-grid-search">Example 2 - Grid Search</h2>
<pre><code class="python">from sklearn import datasets

iris = datasets.load_iris()
X, y = iris.data[:, 1:3], iris.target
</code></pre>

<pre><code class="python">from sklearn.grid_search import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB 
from sklearn.ensemble import RandomForestClassifier
from mlxtend.classifier import EnsembleVoteClassifier

clf1 = LogisticRegression(random_state=1)
clf2 = RandomForestClassifier(random_state=1)
clf3 = GaussianNB()
eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='soft')

params = {'logisticregression__C': [1.0, 100.0],
          'randomforestclassifier__n_estimators': [20, 200],}

grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)
grid.fit(iris.data, iris.target)

for params, mean_score, scores in grid.grid_scores_:
    print(&quot;%0.3f (+/-%0.03f) for %r&quot;
        % (mean_score, scores.std() / 2, params))
</code></pre>

<pre><code>0.953 (+/-0.013) for {'logisticregression__C': 1.0, 'randomforestclassifier__n_estimators': 20}
0.960 (+/-0.012) for {'logisticregression__C': 1.0, 'randomforestclassifier__n_estimators': 200}
0.960 (+/-0.012) for {'logisticregression__C': 100.0, 'randomforestclassifier__n_estimators': 20}
0.953 (+/-0.017) for {'logisticregression__C': 100.0, 'randomforestclassifier__n_estimators': 200}
</code></pre>
<p><strong>Note</strong>: If the <code>EnsembleClassifier</code> is initialized with multiple similar estimator objects, the estimator names are modified with consecutive integer indices, for example:</p>
<pre><code class="python">clf1 = LogisticRegression(random_state=1)
clf2 = RandomForestClassifier(random_state=1)
eclf = EnsembleVoteClassifier(clfs=[clf1, clf1, clf2], voting='soft')

params = {'logisticregression-1__C': [1.0, 100.0],
          'logisticregression-2__C': [1.0, 100.0],
          'randomforestclassifier__n_estimators': [20, 200],}

grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)
grid = grid.fit(iris.data, iris.target)
</code></pre>

<h1 id="api">API</h1>
<p><em>EnsembleVoteClassifier(clfs, voting='hard', weights=None, verbose=0)</em></p>
<p>Soft Voting/Majority Rule classifier for scikit-learn estimators.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>clfs</code> : array-like, shape = [n_classifiers]</p>
<p>A list of classifiers.
Invoking the <code>fit</code> method on the <code>VotingClassifier</code> will fit clones
of those original classifiers that will
be stored in the class attribute
<code>self.clfs_</code>.</p>
</li>
<li>
<p><code>voting</code> : str, {'hard', 'soft'} (default='hard')</p>
<p>If 'hard', uses predicted class labels for majority rule voting.
Else if 'soft', predicts the class label based on the argmax of
the sums of the predicted probalities, which is recommended for
an ensemble of well-calibrated classifiers.</p>
</li>
<li>
<p><code>weights</code> : array-like, shape = [n_classifiers], optional (default=<code>None</code>)</p>
<p>Sequence of weights (<code>float</code> or <code>int</code>) to weight the occurances of
predicted class labels (<code>hard</code> voting) or class probabilities
before averaging (<code>soft</code> voting). Uses uniform weights if <code>None</code>.</p>
</li>
<li>
<p><code>verbose</code> : int, optional (default=0)</p>
<p>Controls the verbosity of the building process.
- <code>verbose=0</code> (default): Prints nothing
- <code>verbose=1</code>: Prints the number &amp; name of the clf being fitted
- <code>verbose=2</code>: Prints info about the parameters of the clf being fitted
- <code>verbose&gt;2</code>: Changes <code>verbose</code> param of the underlying clf to
self.verbose - 2</p>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li>
<p><code>classes_</code> : array-like, shape = [n_predictions]</p>
</li>
<li>
<p><code>clf</code> : array-like, shape = [n_predictions]</p>
<p>The unmodified input classifiers</p>
</li>
<li>
<p><code>clf_</code> : array-like, shape = [n_predictions]</p>
<p>Fitted clones of the input classifiers</p>
</li>
</ul>
<p><strong>Examples</strong></p>
<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression
&gt;&gt;&gt; from sklearn.naive_bayes import GaussianNB
&gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier
&gt;&gt;&gt; from mlxtend.sklearn import EnsembleVoteClassifier
&gt;&gt;&gt; clf1 = LogisticRegression(random_seed=1)
&gt;&gt;&gt; clf2 = RandomForestClassifier(random_seed=1)
&gt;&gt;&gt; clf3 = GaussianNB()
&gt;&gt;&gt; X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
&gt;&gt;&gt; y = np.array([1, 1, 1, 2, 2, 2])
&gt;&gt;&gt; eclf1 = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3],
... voting='hard', verbose=1)
&gt;&gt;&gt; eclf1 = eclf1.fit(X, y)
&gt;&gt;&gt; print(eclf1.predict(X))
[1 1 1 2 2 2]
&gt;&gt;&gt; eclf2 = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='soft')
&gt;&gt;&gt; eclf2 = eclf2.fit(X, y)
&gt;&gt;&gt; print(eclf2.predict(X))
[1 1 1 2 2 2]
&gt;&gt;&gt; eclf3 = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3],
...                          voting='soft', weights=[2,1,1])
&gt;&gt;&gt; eclf3 = eclf3.fit(X, y)
&gt;&gt;&gt; print(eclf3.predict(X))
[1 1 1 2 2 2]
&gt;&gt;&gt;
</code></pre>
<h3 id="methods">Methods</h3>
<hr>

<p><em>fit(X, y)</em></p>
<p>Learn weight coefficients from training data for each classifier.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>self</code> : object</li>
</ul>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<pre><code>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.
</code></pre>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Return estimator parameter names for GridSearch support.</p>
<hr>

<p><em>predict(X)</em></p>
<p>Predict class labels for X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>maj</code> : array-like, shape = [n_samples]</p>
<p>Predicted class labels.</p>
</li>
</ul>
<hr>

<p><em>predict_proba(X)</em></p>
<p>Predict class probabilities for X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>avg</code> : array-like, shape = [n_samples, n_classes]</p>
<p>Weighted average probability for each class per sample.</p>
</li>
</ul>
<hr>

<p><em>score(X, y, sample_weight=None)</em></p>
<p>Returns the mean accuracy on the given test data and labels.</p>
<pre><code>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.
</code></pre>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like, shape = (n_samples, n_features)</p>
<p>Test samples.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = (n_samples) or (n_samples, n_outputs)</p>
<p>True labels for X.</p>
</li>
<li>
<p><code>sample_weight</code> : array-like, shape = [n_samples], optional</p>
<p>Sample weights.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>score</code> : float</p>
<p>Mean accuracy of self.predict(X) wrt. y.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<pre><code>The method works on simple estimators as well as on nested objects
(such as pipelines). The former have parameters of the form
``&lt;component&gt;__&lt;parameter&gt;`` so that it's possible to update each
component of a nested object.
</code></pre>
<p><strong>Returns</strong></p>
<p>self</p>
<hr>

<p><em>transform(X)</em></p>
<p>Return class labels or probabilities for X for each estimator.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>If</code>voting='soft'`` : array-like = [n_classifiers, n_samples, n_classes]</p>
<p>Class probabilties calculated by each classifier.</p>
</li>
<li>
<p><code>If</code>voting='hard'`` : array-like = [n_classifiers, n_samples]</p>
<p>Class labels predicted by each classifier.</p>
</li>
</ul></div>
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Copyright &copy; 2014-2016 <a href="http://sebastianraschka.com">Sebastian Raschka</a><br></small>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="../../../js/jquery-1.10.2.min.js"></script>
    <script src="../../../js/bootstrap-3.0.3.min.js"></script>
    <script src="../../../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '../../..';
    </script>
    <script data-main="../../../mkdocs/js/search.js" src="../../../mkdocs/js/require.js"></script>
    <script src="../../../js/base.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script src="../../../mathjaxhelper.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>
