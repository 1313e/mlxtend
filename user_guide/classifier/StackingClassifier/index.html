<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
    <meta name="author" content="Sebastian Raschka"> 
    <link rel="canonical" href="http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/"> 
    <link rel="shortcut icon" href="../../../../../../favicon.ico">

    <title>StackingClassifier - mlxtend</title>

    <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/font-hack/2.018/css/hack.min.css">
    <link href='//fonts.googleapis.com/css?family=PT+Sans:400,400italic,700,700italic&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../../css/base.css" rel="stylesheet">
    <link href="../../../css/cinder.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../css/highlight.css">


    <link href="../../../extra.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script>
    <script>
    WebFont.load({
        google: {
            families: ['Open Sans', 'PT Sans']
        }
    });
    </script>

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-38457794-2', 'rasbt.github.io/mlxtend/');
    ga('send', 'pageview');
    </script>
    
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->
            <a class="navbar-brand" href="../../..">mlxtend</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">classifier</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../EnsembleVoteClassifier/">EnsembleVoteClassifier</a>
</li>

        
            
<li >
    <a href="../Perceptron/">Perceptron</a>
</li>

        
            
<li >
    <a href="../Adaline/">Adaline</a>
</li>

        
            
<li >
    <a href="../LogisticRegression/">LogisticRegression</a>
</li>

        
            
<li >
    <a href="../NeuralNetMLP/">NeuralNetMLP</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regressor</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regressor/LinearRegression/">LinearRegression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">regression_utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../regression_utils/plot_linear_regression/">Plot linear regression</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">feature_selection</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../feature_selection/SequentialFeatureSelector/">SequentialFeatureSelector</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">evaluate</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../evaluate/confusion_matrix/">Confusion matrix</a>
</li>

        
            
<li >
    <a href="../../evaluate/plot_decision_regions/">Plot decision regions</a>
</li>

        
            
<li >
    <a href="../../evaluate/plot_learning_curves/">Plot learning curves</a>
</li>

        
            
<li >
    <a href="../../evaluate/scoring/">Scoring</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">preprocessing</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../preprocessing/DenseTransformer/">DenseTransformer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/MeanCenterer/">MeanCenterer</a>
</li>

        
            
<li >
    <a href="../../preprocessing/minmax_scaling/">Minmax scaling</a>
</li>

        
            
<li >
    <a href="../../preprocessing/shuffle_arrays_unison/">Shuffle arrays unison</a>
</li>

        
            
<li >
    <a href="../../preprocessing/standardize/">Standardize</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">data</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../data/autompg_data/">Autompg data</a>
</li>

        
            
<li >
    <a href="../../data/boston_housing_data/">Boston housing data</a>
</li>

        
            
<li >
    <a href="../../data/iris_data/">Iris data</a>
</li>

        
            
<li >
    <a href="../../data/mnist_data/">Mnist data</a>
</li>

        
            
<li >
    <a href="../../data/load_mnist/">Load mnist</a>
</li>

        
            
<li >
    <a href="../../data/wine_data/">Wine data</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">file_io</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../file_io/find_filegroups/">Find filegroups</a>
</li>

        
            
<li >
    <a href="../../file_io/find_files/">Find files</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general plotting</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../general_plotting/category_scatter/">Category scatter</a>
</li>

        
            
<li >
    <a href="../../general_plotting/enrichment_plot/">Enrichment plot</a>
</li>

        
            
<li >
    <a href="../../general_plotting/stacked_barplot/">Stacked barplot</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">math</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../math/num_combinations/">Num combinations</a>
</li>

        
            
<li >
    <a href="../../math/num_permutations/">Num permutations</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">text</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../text/generalize_names/">Generalize names</a>
</li>

        
            
<li >
    <a href="../../text/generalize_names_duplcheck/">Generalize names duplcheck</a>
</li>

        
            
<li >
    <a href="../../text/tokenizer/">Tokenizer</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">utils</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../utils/Counter/">Counter</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">general concepts</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../general_concepts/activation-functions/">Activation functions</a>
</li>

        
            
<li >
    <a href="../../general_concepts/gradient-optimization/">Gradient optimization</a>
</li>

        
            
<li >
    <a href="../../general_concepts/linear-gradient-derivative/">Linear gradient derivative</a>
</li>

        
            
<li >
    <a href="../../general_concepts/regularization-linear/">Regularization linear</a>
</li>

        
    </ul>
  </li>

                        
                            
  <li class="dropdown-submenu">
    <a tabindex="-1" href="">Upcoming Features / 0.3.1dev</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../SoftmaxRegression/">SoftmaxRegression</a>
</li>

        
            
<li >
    <a href="../../regressor/StackingRegressor/">StackingRegressor</a>
</li>

        
            
<li class="active">
    <a href="./">StackingClassifier</a>
</li>

        
            
<li >
    <a href="../../preprocessing/one-hot_encoding/">One hot encoding</a>
</li>

        
    </ul>
  </li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.classifier/">Mlxtend.classifier</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.data/">Mlxtend.data</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.evaluate/">Mlxtend.evaluate</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.feature_selection/">Mlxtend.feature selection</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.file_io/">Mlxtend.file io</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.general_plotting/">Mlxtend.general plotting</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.preprocessing/">Mlxtend.preprocessing</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regression_utils/">Mlxtend.regression utils</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.regressor/">Mlxtend.regressor</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.text/">Mlxtend.text</a>
</li>

                        
                            
<li >
    <a href="../../../api_subpackages/mlxtend.utils/">Mlxtend.utils</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li >
                        <a href="../../../installation/">Installation</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../../changelog/">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../../../contributing/">Contributing</a>
</li>

                        
                            
<li >
    <a href="../../../license/">License</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>
            

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                
                    <li >
                        <a rel="next" href="../../regressor/StackingRegressor/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../../preprocessing/one-hot_encoding/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                
                
                    <li>
                        <a href="https://github.com/rasbt/mlxtend">
                            
                                <i class="fa fa-github"></i>
                            
                            GitHub
                        </a>
                    </li>
                
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#stackingclassifier">StackingClassifier</a></li>
        
    
        <li class="main "><a href="#overview">Overview</a></li>
        
            <li><a href="#references">References</a></li>
        
    
        <li class="main "><a href="#examples">Examples</a></li>
        
            <li><a href="#example-1-simple-stacked-classification">Example 1 - Simple Stacked Classification</a></li>
        
            <li><a href="#example-2-stacked-classification-and-gridsearch">Example 2 - Stacked Classification and GridSearch</a></li>
        
    
        <li class="main "><a href="#api">API</a></li>
        
            <li><a href="#methods">Methods</a></li>
        
            <li><a href="#properties">Properties</a></li>
        
    
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h1 id="stackingclassifier">StackingClassifier</h1>
<p>An ensemble-learning meta-classifier for stacking.</p>
<blockquote>
<p>from mlxtend.classifier import StackingClassifier</p>
</blockquote>
<h1 id="overview">Overview</h1>
<p>Stacking is an ensemble learning technique to combine multiple classification models via a meta-classifier. The individual classification models are trained based on the complete training set; then, the meta-classifier is fitted based on the outputs -- meta-features -- of the individual classification models in the ensemble.
The meta-classifier can either be trained on the predicted class labels or probabilities from the ensemble.</p>
<p><img alt="" src="../StackingClassifier_files/stackingclassification_overview.png" /></p>
<p>The algorithm can be summarized as follows (source: [1]):</p>
<p><img alt="" src="../StackingClassifier_files/stacking_algorithm.png" /></p>
<h3 id="references">References</h3>
<ul>
<li>[1] Tang, J., S. Alelyani, and H. Liu. "<a href="https://books.google.com/books?id=nwQZCwAAQBAJ&amp;lpg=PA500&amp;dq=stacking%20classifier%20subsets&amp;pg=PA499#v=onepage&amp;q&amp;f=false">Data Classification: Algorithms and Applications.</a>" Data Mining and Knowledge Discovery Series, CRC Press (2015): pp. 498-500.</li>
<li>[2] Wolpert, David H. "<a href="http://www.sciencedirect.com/science/article/pii/S0893608005800231">Stacked generalization.</a>" Neural networks 5.2 (1992): 241-259.</li>
</ul>
<h1 id="examples">Examples</h1>
<pre><code class="python"># Stacking classifier

# Sebastian Raschka 2014-2016
# mlxtend Machine Learning Library Extensions
#
# An ensemble-learning meta-classifier for stacking
# Author: Sebastian Raschka &lt;sebastianraschka.com&gt;
#
# License: BSD 3 clause

from sklearn.base import BaseEstimator
from sklearn.base import ClassifierMixin
from sklearn.base import TransformerMixin
from sklearn.externals import six
from sklearn.base import clone
from sklearn.pipeline import _name_estimators
import numpy as np


class StackingClassifier(BaseEstimator, ClassifierMixin, TransformerMixin):
    &quot;&quot;&quot;A Stacking classifier for scikit-learn estimators for classification.

    Parameters
    ----------
    classifiers : array-like, shape = [n_regressors]
        A list of classifiers.
        Invoking the `fit` method on the `StackingClassifer` will fit clones
        of these original classifiers that will
        be stored in the class attribute
        `self.clfs_`.
    meta_classifier : object
        The meta-classifier to be fitted on the ensemble of
        classifiers
    use_probas : bool (default: False)
        If True, trains meta-classifier based on predicted probabilities
        instead of class labels.
    verbose : int, optional (default=0)
        Controls the verbosity of the building process.
        - `verbose=0` (default): Prints nothing
        - `verbose=1`: Prints the number &amp; name of the regressor being fitted
        - `verbose=2`: Prints info about the parameters of the
                       regressor being fitted
        - `verbose&gt;2`: Changes `verbose` param of the underlying regressor to
           self.verbose - 2

    Attributes
    ----------
    clfs_ : list, shape=[n_classifiers]
        Fitted classifiers (clones of the original classifiers)
    meta_clf_ : estimator
        Fitted meta-classifier (clone of the original meta-estimator)

    &quot;&quot;&quot;
    def __init__(self, classifiers, meta_classifier, use_probas=False, verbose=0):

        self.classifiers = classifiers
        self.meta_classifier = meta_classifier
        self.named_classifiers = {key: value for
                                  key, value in
                                  _name_estimators(classifiers)}
        self.named_meta_classifier = {'meta-%s' % key: value for
                                      key, value in
                                      _name_estimators([meta_classifier])}
        self.use_probas = use_probas
        self.verbose = verbose

    def fit(self, X, y):
        &quot;&quot;&quot; Fit ensemble classifers and the meta-classifier.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape = [n_samples, n_features]
            Training vectors, where n_samples is the number of samples and
            n_features is the number of features.
        y : array-like, shape = [n_samples]
            Target values.

        Returns
        -------
        self : object

        &quot;&quot;&quot;
        self.clfs_ = [clone(clf) for clf in self.classifiers]
        self.meta_clf_ = clone(self.meta_classifier)
        if self.verbose &gt; 0:
            print(&quot;Fitting %d classifiers...&quot; % (len(self.classifiers)))

        for clf in self.clfs_:

            if self.verbose &gt; 0:
                i = self.clfs_.index(clf) + 1
                print(&quot;Fitting classifier%d: %s (%d/%d)&quot; %
                      (i, _name_estimators((clf,))[0][0], i, len(self.clf_)))

            if self.verbose &gt; 2:
                if hasattr(clf, 'verbose'):
                    clf.set_params(verbose=self.verbose - 2)

            if self.verbose &gt; 1:
                print(_name_estimators((clf,))[0][1])

            clf.fit(X, y)

        meta_features = self._predict_meta_features(X)
        self.meta_clf_.fit(meta_features, y)
        return self

    def get_params(self, deep=True):
        &quot;&quot;&quot;Return estimator parameter names for GridSearch support.&quot;&quot;&quot;
        if not deep:
            return super(StackingClassifier, self).get_params(deep=False)
        else:
            out = self.named_classifiers.copy()
            for name, step in six.iteritems(self.named_classifiers):
                for key, value in six.iteritems(step.get_params(deep=True)):
                    out['%s__%s' % (name, key)] = value

            out.update(self.named_meta_classifier.copy())
            for name, step in six.iteritems(self.named_meta_classifier):
                for key, value in six.iteritems(step.get_params(deep=True)):
                    out['%s__%s' % (name, key)] = value
            return out

    def _predict_meta_features(self, X):
        if self.use_probas:
            probas = np.asarray([clf.predict_proba(X) for clf in self.clfs_])
            vals = np.average(probas, axis=0)
        else:
            vals = np.asarray([clf.predict(X) for clf in self.clfs_]).T
        return vals

    def predict(self, X):
        &quot;&quot;&quot; Predict target values for X.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape = [n_samples, n_features]
            Training vectors, where n_samples is the number of samples and
            n_features is the number of features.

        Returns
        ----------
        labels : array-like, shape = [n_samples]
            Predicted class labels.

        &quot;&quot;&quot;
        meta_features = self._predict_meta_features(X)
        return self.meta_clf_.predict(meta_features)

    def predict_proba(self, X):
        &quot;&quot;&quot; Predict class probabilities for X.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape = [n_samples, n_features]
            Training vectors, where n_samples is the number of samples and
            n_features is the number of features.

        Returns
        ----------
        proba : array-like, shape = [n_samples, n_classes]
            Probability for each class per sample.

        &quot;&quot;&quot;
        meta_features = self._predict_meta_features(X)
        return self.meta_clf_.predict_proba(meta_features)
</code></pre>

<h2 id="example-1-simple-stacked-classification">Example 1 - Simple Stacked Classification</h2>
<pre><code class="python">from sklearn import datasets

iris = datasets.load_iris()
X, y = iris.data[:, 1:3], iris.target
</code></pre>

<pre><code class="python">from sklearn import cross_validation
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB 
from sklearn.ensemble import RandomForestClassifier
import numpy as np

clf1 = KNeighborsClassifier(n_neighbors=1)
clf2 = RandomForestClassifier(random_state=1)
clf3 = GaussianNB()
lr = LogisticRegression()
sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], 
                          meta_classifier=lr)

print('3-fold cross validation:\n')

for clf, label in zip([clf1, clf2, clf3, sclf], 
                      ['KNN', 
                       'Random Forest', 
                       'Naive Bayes',
                       'StackingClassifier']):

    scores = cross_validation.cross_val_score(clf, X, y, cv=3, scoring='accuracy')
    print(&quot;Accuracy: %0.2f (+/- %0.2f) [%s]&quot; % (scores.mean(), scores.std(), label))
</code></pre>

<pre><code>3-fold cross validation:

Accuracy: 0.91 (+/- 0.01) [KNN]
Accuracy: 0.91 (+/- 0.06) [Random Forest]
Accuracy: 0.92 (+/- 0.03) [Naive Bayes]
Accuracy: 0.95 (+/- 0.03) [StackingClassifier]
</code></pre>
<pre><code class="python">import matplotlib.pyplot as plt
from mlxtend.evaluate import plot_decision_regions
import matplotlib.gridspec as gridspec
import itertools

gs = gridspec.GridSpec(2, 2)

fig = plt.figure(figsize=(10,8))

for clf, lab, grd in zip([clf1, clf2, clf3, sclf], 
                         ['KNN', 
                          'Random Forest', 
                          'Naive Bayes',
                          'StackingClassifier'],
                          itertools.product([0, 1], repeat=2)):

    clf.fit(X, y)
    ax = plt.subplot(gs[grd[0], grd[1]])
    fig = plot_decision_regions(X=X, y=y, clf=clf)
    plt.title(lab)
</code></pre>

<p><img alt="png" src="../StackingClassifier_files/StackingClassifier_17_0.png" /></p>
<h2 id="example-2-stacked-classification-and-gridsearch">Example 2 - Stacked Classification and GridSearch</h2>
<p>To set up a parameter grid for scikit-learn's <code>GridSearch</code>, we simply provide the estimator's names in the parameter grid -- in the special case of the meta-regressor, we append the <code>'meta-'</code> prefix.</p>
<pre><code class="python">from sklearn.grid_search import GridSearchCV

# Initializing models

clf1 = KNeighborsClassifier(n_neighbors=1)
clf2 = RandomForestClassifier(random_state=1)
clf3 = GaussianNB()
lr = LogisticRegression()
sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], 
                          meta_classifier=lr)

params = {'kneighborsclassifier__n_neighbors': [1, 5],
          'randomforestclassifier__n_estimators': [10, 50],
          'meta-logisticregression__C': [0.1, 10.0]}

grid = GridSearchCV(estimator=sclf, 
                    param_grid=params, 
                    cv=5,
                    refit=True)
grid.fit(X, y)

for params, mean_score, scores in grid.grid_scores_:
    print(&quot;%0.3f (+/-%0.03f) for %r&quot;
        % (mean_score, scores.std() / 2, params))
</code></pre>

<pre><code>0.667 (+/-0.000) for {'kneighborsclassifier__n_neighbors': 1, 'randomforestclassifier__n_estimators': 10, 'meta-logisticregression__C': 0.1}
0.667 (+/-0.000) for {'kneighborsclassifier__n_neighbors': 1, 'randomforestclassifier__n_estimators': 50, 'meta-logisticregression__C': 0.1}
0.927 (+/-0.022) for {'kneighborsclassifier__n_neighbors': 1, 'randomforestclassifier__n_estimators': 10, 'meta-logisticregression__C': 10.0}
0.913 (+/-0.027) for {'kneighborsclassifier__n_neighbors': 1, 'randomforestclassifier__n_estimators': 50, 'meta-logisticregression__C': 10.0}
0.667 (+/-0.000) for {'kneighborsclassifier__n_neighbors': 5, 'randomforestclassifier__n_estimators': 10, 'meta-logisticregression__C': 0.1}
0.667 (+/-0.000) for {'kneighborsclassifier__n_neighbors': 5, 'randomforestclassifier__n_estimators': 50, 'meta-logisticregression__C': 0.1}
0.933 (+/-0.024) for {'kneighborsclassifier__n_neighbors': 5, 'randomforestclassifier__n_estimators': 10, 'meta-logisticregression__C': 10.0}
0.940 (+/-0.019) for {'kneighborsclassifier__n_neighbors': 5, 'randomforestclassifier__n_estimators': 50, 'meta-logisticregression__C': 10.0}
</code></pre>
<p>In case we are planning to use a regression algorithm multiple times, all we need to do is to add an additional number suffix in the parameter grid as shown below:</p>
<pre><code class="python">from sklearn.grid_search import GridSearchCV

# Initializing models

clf1 = KNeighborsClassifier(n_neighbors=1)
clf2 = RandomForestClassifier(random_state=1)
clf3 = GaussianNB()
lr = LogisticRegression()
sclf = StackingClassifier(classifiers=[clf1, clf1, clf2, clf3], 
                          meta_classifier=lr)

params = {'kneighborsclassifier-1__n_neighbors': [1, 5],
          'kneighborsclassifier-2__n_neighbors': [1, 5],
          'randomforestclassifier__n_estimators': [10, 50],
          'meta-logisticregression__C': [0.1, 10.0]}

grid = GridSearchCV(estimator=sclf, 
                    param_grid=params, 
                    cv=5,
                    refit=True)
grid.fit(X, y)

for params, mean_score, scores in grid.grid_scores_:
    print(&quot;%0.3f (+/-%0.03f) for %r&quot;
        % (mean_score, scores.std() / 2, params))
</code></pre>

<pre><code>0.667 (+/-0.000) for {'randomforestclassifier__n_estimators': 10, 'kneighborsclassifier-1__n_neighbors': 1, 'kneighborsclassifier-2__n_neighbors': 1, 'meta-logisticregression__C': 0.1}
0.667 (+/-0.000) for {'randomforestclassifier__n_estimators': 50, 'kneighborsclassifier-1__n_neighbors': 1, 'kneighborsclassifier-2__n_neighbors': 1, 'meta-logisticregression__C': 0.1}
0.907 (+/-0.029) for {'randomforestclassifier__n_estimators': 10, 'kneighborsclassifier-1__n_neighbors': 1, 'kneighborsclassifier-2__n_neighbors': 1, 'meta-logisticregression__C': 10.0}
0.913 (+/-0.027) for {'randomforestclassifier__n_estimators': 50, 'kneighborsclassifier-1__n_neighbors': 1, 'kneighborsclassifier-2__n_neighbors': 1, 'meta-logisticregression__C': 10.0}
0.667 (+/-0.000) for {'randomforestclassifier__n_estimators': 10, 'kneighborsclassifier-1__n_neighbors': 1, 'kneighborsclassifier-2__n_neighbors': 5, 'meta-logisticregression__C': 0.1}
0.667 (+/-0.000) for {'randomforestclassifier__n_estimators': 50, 'kneighborsclassifier-1__n_neighbors': 1, 'kneighborsclassifier-2__n_neighbors': 5, 'meta-logisticregression__C': 0.1}
0.927 (+/-0.022) for {'randomforestclassifier__n_estimators': 10, 'kneighborsclassifier-1__n_neighbors': 1, 'kneighborsclassifier-2__n_neighbors': 5, 'meta-logisticregression__C': 10.0}
0.913 (+/-0.027) for {'randomforestclassifier__n_estimators': 50, 'kneighborsclassifier-1__n_neighbors': 1, 'kneighborsclassifier-2__n_neighbors': 5, 'meta-logisticregression__C': 10.0}
0.667 (+/-0.000) for {'randomforestclassifier__n_estimators': 10, 'kneighborsclassifier-1__n_neighbors': 5, 'kneighborsclassifier-2__n_neighbors': 1, 'meta-logisticregression__C': 0.1}
0.667 (+/-0.000) for {'randomforestclassifier__n_estimators': 50, 'kneighborsclassifier-1__n_neighbors': 5, 'kneighborsclassifier-2__n_neighbors': 1, 'meta-logisticregression__C': 0.1}
0.927 (+/-0.022) for {'randomforestclassifier__n_estimators': 10, 'kneighborsclassifier-1__n_neighbors': 5, 'kneighborsclassifier-2__n_neighbors': 1, 'meta-logisticregression__C': 10.0}
0.913 (+/-0.027) for {'randomforestclassifier__n_estimators': 50, 'kneighborsclassifier-1__n_neighbors': 5, 'kneighborsclassifier-2__n_neighbors': 1, 'meta-logisticregression__C': 10.0}
0.667 (+/-0.000) for {'randomforestclassifier__n_estimators': 10, 'kneighborsclassifier-1__n_neighbors': 5, 'kneighborsclassifier-2__n_neighbors': 5, 'meta-logisticregression__C': 0.1}
0.667 (+/-0.000) for {'randomforestclassifier__n_estimators': 50, 'kneighborsclassifier-1__n_neighbors': 5, 'kneighborsclassifier-2__n_neighbors': 5, 'meta-logisticregression__C': 0.1}
0.933 (+/-0.024) for {'randomforestclassifier__n_estimators': 10, 'kneighborsclassifier-1__n_neighbors': 5, 'kneighborsclassifier-2__n_neighbors': 5, 'meta-logisticregression__C': 10.0}
0.940 (+/-0.019) for {'randomforestclassifier__n_estimators': 50, 'kneighborsclassifier-1__n_neighbors': 5, 'kneighborsclassifier-2__n_neighbors': 5, 'meta-logisticregression__C': 10.0}
</code></pre>
<h1 id="api">API</h1>
<p><em>StackingClassifier(classifiers, meta_classifier, use_probas=False, verbose=0)</em></p>
<p>A Stacking classifier for scikit-learn estimators for classification.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>classifiers</code> : array-like, shape = [n_regressors]</p>
<p>A list of classifiers.
Invoking the <code>fit</code> method on the <code>StackingClassifer</code> will fit clones
of these original classifiers that will
be stored in the class attribute
<code>self.clfs_</code>.</p>
</li>
<li>
<p><code>meta_classifier</code> : object</p>
<p>The meta-classifier to be fitted on the ensemble of
classifiers</p>
</li>
<li>
<p><code>use_probas</code> : bool (default: False)</p>
<p>If True, trains meta-classifier based on predicted probabilities
instead of class labels.</p>
</li>
<li>
<p><code>verbose</code> : int, optional (default=0)</p>
<p>Controls the verbosity of the building process.
- <code>verbose=0</code> (default): Prints nothing
- <code>verbose=1</code>: Prints the number &amp; name of the regressor being fitted
- <code>verbose=2</code>: Prints info about the parameters of the
regressor being fitted
- <code>verbose&gt;2</code>: Changes <code>verbose</code> param of the underlying regressor to
self.verbose - 2</p>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li>
<p><code>clfs_</code> : list, shape=[n_classifiers]</p>
<p>Fitted classifiers (clones of the original classifiers)</p>
</li>
<li>
<p><code>meta_clf_</code> : estimator</p>
<p>Fitted meta-classifier (clone of the original meta-estimator)</p>
</li>
</ul>
<h3 id="methods">Methods</h3>
<hr>

<p><em>fit(X, y)</em></p>
<p>Fit ensemble classifers and the meta-classifier.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = [n_samples]</p>
<p>Target values.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>self</code> : object</li>
</ul>
<hr>

<p><em>fit_transform(X, y=None, </em><em>fit_params)</em></p>
<p>Fit to data, then transform it.</p>
<pre><code>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.
</code></pre>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : numpy array of shape [n_samples, n_features]</p>
<p>Training set.</p>
</li>
<li>
<p><code>y</code> : numpy array of shape [n_samples]</p>
<p>Target values.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>X_new</code> : numpy array of shape [n_samples, n_features_new]</p>
<p>Transformed array.</p>
</li>
</ul>
<hr>

<p><em>get_params(deep=True)</em></p>
<p>Return estimator parameter names for GridSearch support.</p>
<hr>

<p><em>predict(X)</em></p>
<p>Predict target values for X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>labels</code> : array-like, shape = [n_samples]</p>
<p>Predicted class labels.</p>
</li>
</ul>
<hr>

<p><em>predict_proba(X)</em></p>
<p>Predict class probabilities for X.</p>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>proba</code> : array-like, shape = [n_samples, n_classes]</p>
<p>Probability for each class per sample.</p>
</li>
</ul>
<hr>

<p><em>score(X, y, sample_weight=None)</em></p>
<p>Returns the mean accuracy on the given test data and labels.</p>
<pre><code>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.
</code></pre>
<p><strong>Parameters</strong></p>
<ul>
<li>
<p><code>X</code> : array-like, shape = (n_samples, n_features)</p>
<p>Test samples.</p>
</li>
<li>
<p><code>y</code> : array-like, shape = (n_samples) or (n_samples, n_outputs)</p>
<p>True labels for X.</p>
</li>
<li>
<p><code>sample_weight</code> : array-like, shape = [n_samples], optional</p>
<p>Sample weights.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li>
<p><code>score</code> : float</p>
<p>Mean accuracy of self.predict(X) wrt. y.</p>
</li>
</ul>
<hr>

<p><em>set_params(</em><em>params)</em></p>
<p>Set the parameters of this estimator.</p>
<pre><code>The method works on simple estimators as well as on nested objects
(such as pipelines). The former have parameters of the form
``&lt;component&gt;__&lt;parameter&gt;`` so that it's possible to update each
component of a nested object.
</code></pre>
<p><strong>Returns</strong></p>
<p>self</p>
<h3 id="properties">Properties</h3></div>
        
    </div>

    <footer class="col-md-12 text-center">
        <hr>
        <p>
        <small>Copyright &copy; 2014-2016 <a href="http://sebastianraschka.com">Sebastian Raschka</a><br></small>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p></small>
    </footer>

    <script src="../../../js/jquery-1.10.2.min.js"></script>
    <script src="../../../js/bootstrap-3.0.3.min.js"></script>
    <script src="../../../js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script>
    var base_url = '../../..';
    </script>
    <script data-main="../../../mkdocs/js/search.js" src="../../../mkdocs/js/require.js"></script>
    <script src="../../../js/base.js"></script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <script src="../../../mathjaxhelper.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <button type="button" class="close" data-dismiss="modal">
                        <span aria-hidden="true">&times;</span>
                        <span class="sr-only">Close</span>
                    </button>
                    <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                </div>
                <div class="modal-body">
                    <p>
                        From here you can search these documents. Enter your search terms below.
                    </p>
                    <form role="form">
                        <div class="form-group">
                            <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                        </div>
                    </form>
                    <div id="mkdocs-search-results"></div>
                </div>
                <div class="modal-footer">
                </div>
            </div>
        </div>
    </div>

    </body>

</html>
