{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebastian Raschka, 2015  \n",
    "`mlxtend`, a library of extension and helper modules for Python's data analysis and machine learning libraries\n",
    "\n",
    "- GitHub repository: https://github.com/rasbt/mlxtend\n",
    "- Documentation: http://rasbt.github.io/mlxtend/\n",
    "\n",
    "View this page in [jupyter nbviewer](http://nbviewer.ipython.org/github/rasbt/mlxtend/blob/master/docs/sources/_ipynb_templates/regressor/linear_regression.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "Last updated: 12/11/2015 \n",
      "\n",
      "CPython 3.5.0\n",
      "IPython 4.0.0\n",
      "\n",
      "matplotlib 1.5.0\n",
      "numpy 1.10.1\n",
      "scipy 0.16.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -u -d -v -p matplotlib,numpy,scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0dev'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../../mlxtend/')\n",
    "\n",
    "import mlxtend\n",
    "mlxtend.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of a multilayer perceptron, a feedforward artificial neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> from mlxtend.classifier import NeuralNetMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Although the code is fully working and can be used for common classification tasks, this implementation is not geared towards efficiency but clarity â€“ the original code was written for demonstration purposes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/neuralnet_mlp_1.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neurons $x_0$ and $a_0$ represent the bias units ($x_0=1$, $a_0=1$). In the current implementation, the activation is computed as\n",
    "\n",
    "$$\\phi(z) = \\frac{1}{1 + e^{-z}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note: *x*<sub>0</sub> and *a*<sub>0</sub> are the bias units ( *x*<sub>0</sub>=1, *a*<sub>0</sub>=1); the activation is calculated as   *sigmoid(z) = g(z) = 1 / (1+exp(-z))*,   where the net input ***z*** of the first layer is defined as  ***z***<sup>(2)</sup> = **w**<sup>(1)</sup>***a***<sup>(1)</sup><sup>T</sup>, and the net input of the second layer is defined as  ***z***<sup>(3)</sup> = ***w***<sup>(2)</sup>***a***<sup>(2)</sup>, respectively; ***w***<sup>(k)</sup> are the weight matrices of the corresponding layers; ***a***<sup>(1)</sup> is equal to the input features plus bias unit, ***a***<sup>(1)</sup> = [1,  ***x*** ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Topics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 - Classifying Iris Flowers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load 2 features from Iris (petal length and petal width) for visualization purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.data import iris_data\n",
    "X, y = iris_data()\n",
    "X = X[:, 2:]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train neural network for 3 output flower classes ('Setosa', 'Versicolor', 'Virginica'), regular gradient decent (`minibatches=1`), 30 hidden units, and no regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.classifier import NeuralNetMLP\n",
    "import numpy as np\n",
    "nn1 = NeuralNetMLP(n_output=3, \n",
    "      n_features=X.shape[1], \n",
    "      n_hidden=30, \n",
    "...     l2=0.0, \n",
    "...     l1=0.0, \n",
    "...     epochs=5000, \n",
    "...     eta=0.001, \n",
    "...     alpha=0.1,\n",
    "...     minibatches=1, \n",
    "...     shuffle=True,\n",
    "...     random_state=1)\n",
    ">>> nn1.fit(X, y)\n",
    ">>> y_pred = nn1.predict(X)\n",
    ">>> acc = np.sum(y == y_pred, axis=0) / X.shape[0]\n",
    ">>> print('Accuracy: %.2f%%' % (acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NeuralNetMLP in module mlxtend.classifier.neuralnet_mlp:\n",
      "\n",
      "class NeuralNetMLP(builtins.object)\n",
      " |  Feedforward neural network / Multi-layer perceptron classifier.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ------------\n",
      " |  n_output : int\n",
      " |    Number of output units, should be equal to the\n",
      " |    number of unique class labels.\n",
      " |  \n",
      " |  n_features : int\n",
      " |    Number of features (dimensions) in the target dataset.\n",
      " |    Should be equal to the number of columns in the X array.\n",
      " |  \n",
      " |  n_hidden : int (default: 30)\n",
      " |    Number of hidden units.\n",
      " |  \n",
      " |  l1 : float (default: 0.0)\n",
      " |    Lambda value for L1-regularization.\n",
      " |    No regularization if l1=0.0 (default)\n",
      " |  \n",
      " |  l2 : float (default: 0.0)\n",
      " |    Lambda value for L2-regularization.\n",
      " |    No regularization if l2=0.0 (default)\n",
      " |  \n",
      " |  epochs : int (default: 500)\n",
      " |    Number of passes over the training set.\n",
      " |  \n",
      " |  eta : float (default: 0.001)\n",
      " |    Learning rate.\n",
      " |  \n",
      " |  alpha : float (default: 0.0)\n",
      " |    Momentum constant. Factor multiplied with the\n",
      " |    gradient of the previous epoch t-1 to improve\n",
      " |    learning speed\n",
      " |    w(t) := w(t) - (grad(t) + alpha*grad(t-1))\n",
      " |  \n",
      " |  decrease_const : float (default: 0.0)\n",
      " |    Decrease constant. Shrinks the learning rate\n",
      " |    after each epoch via eta / (1 + epoch*decrease_const)\n",
      " |  \n",
      " |  random_weights : list (default: [-1.0, 1.0])\n",
      " |    Min and max values for initializing the random weights.\n",
      " |    Initializes weights to 0 if None or False.\n",
      " |  \n",
      " |  shuffle_init : bool (default: True)\n",
      " |    Shuffles (a copy of the) training data before training.\n",
      " |  \n",
      " |  shuffle_epoch : bool (default: True)\n",
      " |    Shuffles training data before every epoch if True to prevent circles.\n",
      " |  \n",
      " |  minibatches : int (default: 1)\n",
      " |    Divides training data into k minibatches for efficiency.\n",
      " |    Normal gradient descent learning if k=1 (default).\n",
      " |  \n",
      " |  random_state : int (default: None)\n",
      " |    Set random state for shuffling and initializing the weights.\n",
      " |  \n",
      " |  Attributes\n",
      " |  -----------\n",
      " |  cost_ : list\n",
      " |    Sum of squared errors after each epoch.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_output, n_features, n_hidden=30, l1=0.0, l2=0.0, epochs=500, eta=0.001, alpha=0.0, decrease_const=0.0, random_weights=[-1.0, 1.0], shuffle_init=True, shuffle_epoch=True, minibatches=1, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, print_progress=False)\n",
      " |      Learn weights from training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : array, shape = [n_samples, n_features]\n",
      " |        Input layer with original features.\n",
      " |      \n",
      " |      y : array, shape = [n_samples]\n",
      " |        Target class labels.\n",
      " |      \n",
      " |      print_progress : bool (default: False)\n",
      " |        Prints progress as the number of epochs\n",
      " |        to stderr.\n",
      " |      \n",
      " |      Returns:\n",
      " |      ----------\n",
      " |      self\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : array, shape = [n_samples, n_features]\n",
      " |        Input layer with original features.\n",
      " |      \n",
      " |      Returns:\n",
      " |      ----------\n",
      " |      y_pred : array, shape = [n_samples]\n",
      " |        Predicted class labels.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import NeuralNetMLP\n",
    "help(NeuralNetMLP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
