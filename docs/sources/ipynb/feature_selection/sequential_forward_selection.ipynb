{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path = ['../../../..'] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0dev'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlxtend\n",
    "mlxtend.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Sebastian Raschka 10/19/2015 \n",
      "\n",
      "CPython 3.5.0\n",
      "IPython 4.0.0\n",
      "\n",
      "scikit-learn 0.16.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -d -v -p scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Forward Selection\n",
    "\n",
    "> from mlxtend.feature_selection import SFS\n",
    "\n",
    "Sequential Forward Selection (SFS) is a classic feature selection algorithm -- a greedy search algorithm -- that has been developed as a suboptimal solution to the computationally often not feasible exhaustive search. In a nutshell, SFS adds one feature from the original feature set at the time, based on the classifier performance, until a feature subset of the desired size *k* is reached.\n",
    "\n",
    "\n",
    "***Related topics:***\n",
    "\n",
    "- [Sequential Backward Selection](./sequential_backward_selection.md)\n",
    "- [Sequential Floating Forward Selection](./sequential_floating_forward_selection.md)\n",
    "- [Sequential Floating Backward Selection](./sequential_floating_backward_selection.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### The SFFS Algorithm\n",
    "\n",
    "\n",
    "\n",
    "**Input:** $Y = \\{y_1, y_2, ..., y_d\\}$  \n",
    "\n",
    "- The ***SFS*** algorithm takes the whole $d$-dimensional feature set as input.\n",
    "\n",
    "\n",
    "**Output:** $X_k = \\{x_j \\; | \\;j = 1, 2, ..., k; \\; x_j \\in Y\\}$, where $k = (0, 1, 2, ..., d)$\n",
    "\n",
    "- SFS returns a subset of features; the number of selected features $k$, where $k < d$, has to be specified *a priori*.\n",
    "\n",
    "**Initialization:** $X_0 = \\emptyset$, $k = 0$\n",
    "\n",
    "- We initialize the algorithm with an empty set $\\emptyset$ (\"null set\") so that $k = 0$ (where $k$ is the size of the subset).\n",
    "\n",
    "**Step 1 (Inclusion):**  \n",
    "\n",
    "  $x^+ = \\text{ arg max } J(x_k + x), \\text{ where }  x \\in Y - X_k$  \n",
    "  $X_k+1 = X_k + x^+$  \n",
    "  $k = k + 1$    \n",
    "*Go to Step 2*\n",
    "\n",
    "- in this step, we add an additional feature, $x^+$, to our feature subset $X_k$.\n",
    "- $x^+$ is the feature that maximizes our criterion function, that is, the feature that is associated with the best classifier performance if it is added to $X_k$.\n",
    "\n",
    "**Step 2 (Conditional Exclusion):**  \n",
    "\n",
    "$x^- = \\text{ arg max } J(x_k - x), \\text{ where } x \\in X_k$  \n",
    "$if \\; J(x_k - x) > J(x_k - x)$:    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $X_k-1 = X_k - x^-$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $k = k - 1$    \n",
    "*Go to Step 1*  \n",
    "\n",
    "- In Step 2, we only remove a feature if the resulting subset would gain an increase in performance. We go back to Step 1.  \n",
    "- Steps 1 and 2 are reapeated until the **Termination** criterion is reached.\n",
    "\n",
    "**Termination:** $k = p$\n",
    "\n",
    "- We add features from the feature subset $X_k$ until the feature subset of size $k$ contains the number of desired features $p$ that we specified *a priori*.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 2/2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of selected features: (2, 3)\n",
      "CV score of selected subset: 0.966666666667\n",
      "New feature subset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.4,  0.2],\n",
       "       [ 1.4,  0.2],\n",
       "       [ 1.3,  0.2],\n",
       "       [ 1.5,  0.2],\n",
       "       [ 1.4,  0.2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SFS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "sfs = SFS(knn, k_features=2, scoring='accuracy', cv=5)\n",
    "sfs.fit(X, y)\n",
    "\n",
    "print('Indices of selected features:', sfs.indices_)\n",
    "print('CV score of selected subset:', sfs.k_score_)\n",
    "print('New feature subset:')\n",
    "sfs.transform(X)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Data Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 13/13"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEPCAYAAABcA4N7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a70f5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scr = StandardScaler()\n",
    "X_std = scr.fit_transform(X)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "# selecting features\n",
    "sfs = SFS(knn, k_features=13, scoring='accuracy', cv=5)\n",
    "sfs.fit(X_std, y)\n",
    "\n",
    "# plotting performance of feature subsets\n",
    "k_feat = [len(k) for k in sfs.subsets_]\n",
    "\n",
    "plt.plot(k_feat, sfs.scores_, marker='o')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the number of features in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 1/1[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "Features: 4/4[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    1.1s finished\n",
      "Features: 1/1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best score: 0.960\n",
      "Best parameters set:\n",
      "\tsel__k_features: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from mlxtend.feature_selection import SFS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "##########################\n",
    "### Loading data\n",
    "##########################\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "##########################\n",
    "### Setting up pipeline\n",
    "##########################\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "sfs = SFS(estimator=knn, k_features=2, scoring='accuracy', cv=5)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "            ('scr', StandardScaler()), \n",
    "            ('sel', sfs),\n",
    "            ('clf', knn)])\n",
    "\n",
    "parameters = {'sel__k_features': [1,2,3,4]}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=1)\n",
    "\n",
    "##########################\n",
    "### Running GridSearch\n",
    "##########################\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the estimator used for feature selection. Note that the current implementation requires to search for the weights in both the classifier and the SBS transformer separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 1/1[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "Features: 1/1[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    4.6s\n",
      "Features: 4/4[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:   10.2s finished\n",
      "Features: 2/2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best score: 0.973\n",
      "Best parameters set:\n",
      "\tclf__n_neighbors: 5\n",
      "\tsel__estimator__n_neighbors: 5\n",
      "\tsel__k_features: 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from mlxtend.feature_selection import SFS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "##########################\n",
    "### Loading data\n",
    "##########################\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "##########################\n",
    "### Setting up pipeline\n",
    "##########################\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "sfs = SFS(estimator=knn, k_features=2, scoring='accuracy', cv=5)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "            ('scr', StandardScaler()), \n",
    "            ('sel', sfs),\n",
    "            ('clf', knn)])\n",
    "\n",
    "parameters = {'sel__k_features': [1, 2, 3, 4],\n",
    "              'sel__estimator__n_neighbors': [4, 5, 6],\n",
    "              'clf__n_neighbors': [4, 5, 6]}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=1)\n",
    "\n",
    "##########################\n",
    "### Running GridSearch\n",
    "##########################\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final feature subset can then be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature subset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best feature subset:')\n",
    "grid_search.best_estimator_.steps[1][1].indices_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SFS in module mlxtend.feature_selection.sequential_forward_select:\n",
      "\n",
      "class SFS(sklearn.base.BaseEstimator, sklearn.base.MetaEstimatorMixin)\n",
      " |  Sequential Forward Selection for feature selection.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : scikit-learn estimator object\n",
      " |  \n",
      " |  print_progress : bool (default: True)\n",
      " |     Prints progress as the number of epochs\n",
      " |     to stderr.\n",
      " |  \n",
      " |  k_features : int\n",
      " |    Number of features to select where k_features.\n",
      " |  \n",
      " |  scoring : str, (default='accuracy')\n",
      " |    Scoring metric for the cross validation scorer.\n",
      " |  \n",
      " |  cv : int (default: 5)\n",
      " |    Number of folds in StratifiedKFold.\n",
      " |  \n",
      " |  n_jobs : int (default: 1)\n",
      " |    The number of CPUs to use for cross validation. -1 means 'all CPUs'.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  indices_ : array-like, shape = [n_predictions]\n",
      " |    Indices of the selected subsets.\n",
      " |  \n",
      " |  k_score_ : float\n",
      " |    Cross validation mean score of the selected subset\n",
      " |  \n",
      " |  subsets_ : list of tuples\n",
      " |    Indices of the sequentially selected subsets.\n",
      " |  \n",
      " |  scores_ : list\n",
      " |    Cross validation mean scores of the sequentially selected subsets.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> iris = load_iris()\n",
      " |  >>> X = iris.data\n",
      " |  >>> y = iris.target\n",
      " |  >>> knn = KNeighborsClassifier(n_neighbors=4)\n",
      " |  >>> sfs = SFS(knn, k_features=2, scoring='accuracy', cv=5)\n",
      " |  >>> sfs = sfs.fit(X, y)\n",
      " |  >>> sfs.indices_\n",
      " |  (2, 3)\n",
      " |  >>> sfs.transform(X[:5])\n",
      " |  array([[ 1.4,  0.2],\n",
      " |         [ 1.4,  0.2],\n",
      " |         [ 1.3,  0.2],\n",
      " |         [ 1.5,  0.2],\n",
      " |         [ 1.4,  0.2]])\n",
      " |  \n",
      " |  >>> print('best score: %.2f' % sfs.k_score_)\n",
      " |  best score: 0.97\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SFS\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, k_features, print_progress=True, scoring='accuracy', cv=5, n_jobs=1)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |  \n",
      " |  fit_transform(self, X, y)\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep: boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The former have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SFS\n",
    "help(SFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
