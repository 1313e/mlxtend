{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka 29/04/2015 \n",
      "\n",
      "CPython 3.4.3\n",
      "IPython 3.1.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -d -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path = ['/Users/sebastian/github/mlxtend/'] + sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "- [Introduction to Sequential Backward Selection](#Introduction-to-Sequential-Backward-Selection)\n",
    "    - [Further Reading](#Further-Reading)\n",
    "- [Iris Example](#Iris-Example)\n",
    "- [Wine Data Example](#Wine-Data-Example)\n",
    "- [Gridsearch Example 1](#Gridsearch-Example-1)\n",
    "- [Gridsearch Example 2](#Gridsearch-Example-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Sequential Backward Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid the Curse of Dimensionality, pattern classification is often accompanied by Dimensionality Reduction, which also has the nice side-effect of increasing the computational performance. Common techniques are projection-based, such as Principal Component Analysis (PCA) (unsupervised) or Linear Discriminant (LDA) (supervised). It shall be noted though that regularization in classification models such as Logistic Regression, Support Vector Machines, or Neural Networks is to be preferred over using dimensionality reduction to avoid overfitting. However, dimensionality reduction is still a useful data compression technique to increase computational efficiency and data storage problems.\n",
    "\n",
    "An alternative to a projection-based dimensionality reduction approach is the so-called Feature Selection, and here, we will take a look at some of the established algorithms to tackle this combinatorial search problem: Sequential Backward Selection (SBS). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize its mechanics in words:\n",
    "SBS starts with the original $d$-dimensional feature set and sequentially removes features from this set until the subset reaches a desired (user-specified) size $k$ where $k < d$. In every iteration $i$, the subset $d-i$ dimensional subset is evaluated using a criterion function to determine the least informative feature to be removed.\n",
    "\n",
    "The criterion function is typically the performance of the classifier measured via cross validation. \n",
    "\n",
    "Let's consider the following example where we have a dataset that consists of 3 features:\n",
    "\n",
    "\n",
    "- Original feature set: $\\{x_1, x_2, x_3\\}$\n",
    "\n",
    "In order to determine the least informative feature, we create 2-dimensional feature subsets and measure the performance (e.g., accuracy) of the classifier on each of those subset:\n",
    "\n",
    "- 1: $\\{x_1, x_2\\}$ -> 0.96\n",
    "- 2: $\\{x_1, x_3\\}$ -> 0.87\n",
    "- 3: $\\{x_2, x_3\\}$ -> 0.77\n",
    "\n",
    "Based on the accuracy measures, we would then eliminate feature $x_3$ and repeat this procedure until we reached the number of features to select. E.g., if we'd want to select 2 features, we'd stop at this point and select the feature subset $\\{x_1, x_2$\\}.\n",
    "\n",
    "Note that this algorithm is considered as \"subpoptimal\" in contrast to an exhaustive search, which is often computationally not feasible, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Sections)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F. Ferri, P. Pudil, M. Hatef, and J. Kittler investigated the performance of different Sequential Selection Algorithms for Feature Selection on different scales and reported their results in\n",
    "\n",
    "- [\"Comparative Study of Techniques for Large Scale Feature Selection,\"](https://books.google.com/books?id=sbajBQAAQBAJ&pg=PA403&lpg=PA403&dq=Comparative+Study+of+Techniques+for+Large+Scale+Feature+Selection&source=bl&ots=KdGKWqzbzj&sig=5I9nhy-TrRmKyAiLDfy5ML_m578&hl=en&sa=X&ei=i7w-VYnoPMyXsAWm2IGgCw&ved=0CD4Q6AEwBA#v=onepage&q=Comparative%20Study%20of%20Techniques%20for%20Large%20Scale%20Feature%20Selection&f=false) Pattern Recognition in Practice IV, E. Gelsema and L. Kanal, eds., pp. 403-413. Elsevier Science B.V., 1994.\n",
    "\n",
    "Choosing an \"appropriate\" algorithm really depends on the problem - the size and desired recognition rate and computational performance. Thus, I want to encourage you to take (at least) a brief look at their paper and the results they obtained from experimenting with different problems feature space dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Sections)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of selected features: (0, 3)\n",
      "CV score of selected subset: 0.96\n",
      "New feature subset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  0.2],\n",
       "       [ 4.9,  0.2],\n",
       "       [ 4.7,  0.2],\n",
       "       [ 4.6,  0.2],\n",
       "       [ 5. ,  0.2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.sklearn import SBS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "sbs = SBS(knn, k_features=2, scoring='accuracy', cv=5)\n",
    "sbs.fit(X, y)\n",
    "\n",
    "print('Indices of selected features:', sbs.indices_)\n",
    "print('CV score of selected subset:', sbs.k_score_)\n",
    "print('New feature subset:')\n",
    "sbs.transform(X)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Data Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Sections)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEPCAYAAABcA4N7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107fb1a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scr = StandardScaler()\n",
    "X_std = scr.fit_transform(X)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "# selecting features\n",
    "sbs = SBS(knn, k_features=1, scoring='accuracy', cv=5)\n",
    "sbs.fit(X_std, y)\n",
    "\n",
    "# plotting performance of feature subsets\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Sections)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the number of features in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best score: 0.960\n",
      "Best parameters set:\n",
      "\tsel__k_features: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from mlxtend.sklearn import SBS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "##########################\n",
    "### Loading data\n",
    "##########################\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "##########################\n",
    "### Setting up pipeline\n",
    "##########################\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "sbs = SBS(estimator=knn, k_features=2, scoring='accuracy', cv=5)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "            ('scr', StandardScaler()), \n",
    "            ('sel', sbs),\n",
    "            ('clf', knn)])\n",
    "\n",
    "parameters = {'sel__k_features': [1,2,3,4]}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=1)\n",
    "\n",
    "##########################\n",
    "### Running GridSearch\n",
    "##########################\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Sections)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the estimator used for feature selection. Note that the current implementation requires to search for the weights in both the classifier and the SBS transformer separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best score: 0.973\n",
      "Best parameters set:\n",
      "\tclf__n_neighbors: 5\n",
      "\tsel__estimator__n_neighbors: 5\n",
      "\tsel__k_features: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:    6.0s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from mlxtend.sklearn import SBS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "##########################\n",
    "### Loading data\n",
    "##########################\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "##########################\n",
    "### Setting up pipeline\n",
    "##########################\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "sbs = SBS(estimator=knn, k_features=2, scoring='accuracy', cv=5)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "            ('scr', StandardScaler()), \n",
    "            ('sel', sbs),\n",
    "            ('clf', knn)])\n",
    "\n",
    "parameters = {'sel__k_features': [1, 2, 3, 4],\n",
    "              'sel__estimator__n_neighbors': [4, 5, 6],\n",
    "              'clf__n_neighbors': [4, 5, 6]}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=1)\n",
    "\n",
    "##########################\n",
    "### Running GridSearch\n",
    "##########################\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final feature subset can then be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature subset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best feature subset:')\n",
    "grid_search.best_estimator_.steps[1][1].indices_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
